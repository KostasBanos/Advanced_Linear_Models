[
  {
    "objectID": "Project_4.html#analysis-of-the-olympics-dataset",
    "href": "Project_4.html#analysis-of-the-olympics-dataset",
    "title": "Project 4",
    "section": "1. Analysis of the Olympics Dataset",
    "text": "1. Analysis of the Olympics Dataset\n\n# Improt and convert the data to tibble\nolymp &lt;- read.csv(url(\"https://raw.githubusercontent.com/bbolker/stats720/main/data/olymp1.csv\"))\nolymp &lt;- as_tibble(olymp)\n\ngdp_per_cap &lt;- olymp$gdp/olymp$pop ## GDP per Capita\nlog_gdp &lt;- log(olymp$gdp)          ## Logarithm of GDP\nlog_pop &lt;- log(olymp$pop)          ## Logarithm of Population\nlog_gdp_perC &lt;- log_gdp-log_pop    ## Logarithm of GDP per Capita\nlog_n &lt;- log(olymp$n+1)            ## Logarithm of the Number of Medals\nlog_year &lt;- log(olymp$year)\n\n\n## Add six new columns using mutate to the olymp dataset\n\n olymp &lt;- olymp %&gt;%\n  mutate(gdp_per_cap = gdp_per_cap,,\n         log_gdp = log_gdp,\n         log_pop = log_pop,\n         log_gdp_perC = log_gdp_perC,\n         log_n = log_n,\n         log_year = log_year)\n    \n \nmydata = olymp |&gt; filter(medal == \"Gold\")       ## Filtering by \"Gold\" Metal and creation of a new dataset \nmydata &lt;- mydata %&gt;%\n  mutate(centered_year = year - mean(year, na.rm = TRUE),\n         centered_log_year = log_year - mean(log_year, na.rm = TRUE),\n         centered_log_pop = log_pop - mean(log_pop, na.rm = TRUE),\n         wealthy_class = case_when(\n    log_gdp_perC &lt;= 0.5 ~ 1,                      # If log_gdp_perC &lt; 0, wealthy_class = 1\n    log_gdp_perC &gt; 0.5 & log_gdp_perC &lt;= 2 ~ 2,   # If log_gdp_perC between 0 and 2, wealthy_class = 2\n    log_gdp_perC &gt; 2 & log_gdp_perC &lt;= 3.5 ~ 3,   # If log_gdp_perC between 2 and 4, wealthy_class = 3\n    log_gdp_perC &gt; 3.5 ~ 4,                       # If log_gdp_perC &gt; 4, wealthy_class = 4\n      ))\nmydata$team &lt;- as.factor(mydata$team)\nmydata$wealthy_class &lt;- as.numeric(mydata$wealthy_class)\nmydata &lt;- mydata[!is.na(mydata$log_pop) & !is.na(mydata$log_gdp) &\n                       !is.infinite(mydata$log_pop) & !is.infinite(mydata$log_gdp), ]\n\n\nhead(mydata,10)\n\n# A tibble: 10 × 16\n   team   year medal     n    gdp   pop gdp_per_cap log_gdp log_pop log_gdp_perC\n   &lt;fct&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt;  &lt;dbl&gt; &lt;dbl&gt;       &lt;dbl&gt;   &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;\n 1 Afgh…  2000 Gold      0   6.21  19.5       0.318    1.83    2.97       -1.15 \n 2 Afgh…  2004 Gold      0   7.98  23.6       0.339    2.08    3.16       -1.08 \n 3 Afgh…  2008 Gold      0  11.1   26.4       0.419    2.40    3.27       -0.871\n 4 Afgh…  2012 Gold      0  17.4   30.5       0.571    2.86    3.42       -0.561\n 5 Afgh…  2016 Gold      0  19.6   34.6       0.565    2.97    3.54       -0.571\n 6 Alge…  2000 Gold      1 110.    30.8       3.57     4.70    3.43        1.27 \n 7 Alge…  2004 Gold      0 133.    32.5       4.08     4.89    3.48        1.41 \n 8 Alge…  2008 Gold      0 152.    34.6       4.40     5.02    3.54        1.48 \n 9 Alge…  2012 Gold      1 170.    37.3       4.57     5.14    3.62        1.52 \n10 Alge…  2016 Gold      0 195.    40.3       4.83     5.27    3.70        1.57 \n# ℹ 6 more variables: log_n &lt;dbl&gt;, log_year &lt;dbl&gt;, centered_year &lt;dbl&gt;,\n#   centered_log_year &lt;dbl&gt;, centered_log_pop &lt;dbl&gt;, wealthy_class &lt;dbl&gt;\n\n## table(mydata$wealthy_class)\n## hist(log_gdp_perC)\n\nIn this analysis, the focus was on estimating gold medals from the olymp1 dataset. After importing the dataset, it was transformed into a tibble format for more convenient handling. Five new variables were created by applying a logarithmic transformation to five key variables, reducing their dispersion and ensuring a smoother dataset for further analysis. Subsequently, a new tibble (mydata) was created, filtered to include only observations related to gold medals. This filtered dataset serves as the primary basis for the following analysis.\nThe mydata dataset is a filtered subset of the Olympic dataset, containing observations exclusively for countries that earned “Gold” medals. It comprises variables detailing economic and demographic characteristics of nations, along with their Olympic performance metrics. The dataset includes 16 variables: team (factor indicating the country’s name), year (year of the Olympic event), medal (medal type, fixed as “Gold”), n (number of gold medals), gdp (Gross Domestic Product), pop (population), and derived variables such as gdp_per_cap (GDP per capita), log_gdp, log_pop, log_gdp_perC (logarithmic transformations of GDP, population, and GDP per capita), and log_n (logarithmic transformation of medal count). Additionally, it features time-centered variables (centered_year and centered_log_year) and a derived categorical variable, wealthy_class, which classifies nations into wealth tiers based on their logarithmic GDP per capita. Observations with missing or infinite values for log_pop or log_gdp were excluded to ensure data integrity.\n\na) Maximal Model Specification for Predicting Olympic Medal Counts with Fixed and Random Effects\n\nModel Specification\nFollowing the recommendations of Barr et al. (2013), we will begin with the maximal model to account for all theoretically justified random effects. This approach prioritizes capturing the structure of the experimental design to avoid anti-conservative inferences. If singularity or non-convergence issues arise, we will iteratively simplify the random-effects structure while maintaining theoretical plausibility.\n\n\nResponse Variable\nThe dependent variable for this analysis is the number of gold medals won (n), a count variable.\n\n\nFixed Effects\nWe will include the following fixed effects:\n\nLogarithm of population (log_pop): This variable accounts for the size of the population, which can influence the likelihood of winning gold medals.\nLogarithm of GDP (log_gdp): Captures economic strength, hypothesized to correlate with investment in sports.\nCentered year (centered_year​): Centering the year ensures more interpretable estimates and captures variability associated with time trends.\nWealth class (wealthy_class): Categorizes countries into economic groups to facilitate insights into disparities between economic classes.\n\n\n\nRandom Effects\nThe random-effects structure will model the variability attributable to teams (i.e., countries). Specifically, we will include:\n\nA random intercept to account for baseline differences in medal counts across teams.\nRandom slopes for each fixed effect, allowing their effects to vary among teams.\n\n\n\nStatistical Model\nGiven that the response variable is a count, we will use a generalized linear mixed-effects model with one of the following families:\n\nPoisson regression if the count data follows the Poisson distribution.\nNegative binomial regression if overdispersion is detected (variance exceeds the mean).\n\n\n\nJustification of Model Components\n\nWealth Class as a Fixed Effect: As noted by Gelman (2006), treating wealth class as a random effect is not appropriate given the small number of clusters (&lt;5). Including it as a fixed effect ensures numerical stability.\nRandom Effects for Team: This accounts for unobserved heterogeneity among teams, improving the generalizability of the model.\n\nThis approach allows for a robust analysis that accounts for both fixed and random effects while addressing the characteristics of count data\n\n\n\nb) When to Include a Random Effects Term for Country × Year in Mixed-Effects Models: Key Considerations\nIncluding a random effects term with the grouping variable country:year is appropriate when there is variability across the combinations of countries and years that cannot be explained by the fixed effects. This is especially relevant when the response variable is continuous and there are multiple observations per combination of country:year, such as when the data includes repeated measures of the same countries across different years. The random effects term accounts for the correlation of observations within each country-year combination, providing a more accurate estimate of the fixed effects by adjusting for unobserved heterogeneity. It is also suitable when the response distribution is Gaussian, as random effects models are robust for continuous data, where within-group correlation needs to be modeled for unbiased inference.\nOn the other hand, if most country:year combinations have only one or two observations (as in the case of countries winning medals in a particular year), the random effects cannot reliably capture variability within these groups. It doesn’t make sense to include a random effect in the form of country:year when the distribution does not have a scale parameter because random effects are fundamentally tied to modeling variance components within a distribution. In distributions that lack a scale parameter, such as the Poisson or binomial distributions, the variance is inherently linked to the mean (in Poisson, the variance equals the mean, and in binomial, the variance is a function of both the probability of success and the number of trials). Random effects in such models are typically used to account for unexplained variability or correlation in the data. For distributions without a scale parameter, there is no independent variance to estimate, so introducing random effects may lead to model misspecification. In other words, the random effects term may not have any meaningful interpretation because the model already incorporates the necessary dependency structure through the mean-variance relationship of the distribution.\nFor example:\n\nPoisson regression models count data, where the variance is tied directly to the mean. Adding a random effect term like country:year might result in overfitting or unnecessary complexity, as the scale of the distribution is constrained by the mean.\nBinomial regression models proportions, where the variance also depends on the mean. Introducing a random effect term under these conditions can be redundant and could distort the model’s behavior, especially when the data has relatively few observations per group or when variance already naturally scales with the mean.\n\nIn these cases, more appropriate methods like fixed-effects models or generalized estimating equations (GEE) may be preferred, as they focus on capturing correlations within clustered data without assuming a separate variance component that random effects require.\n\n\nc and d) Defining the Initial Model: Balancing Complexity and Practicality and Visualizing the Dataset\nGiven the inherent nature of the problem, I have decided to employ a generalized mixed-effects model from either the Poisson or negative binomial family. The choice of the specific family will be guided by several key factors, including the level of dispersion in the data, the presence of zero inflation, and other distributional characteristics. I have opted not to use the maximal model due to its relative complexity and the high likelihood of encountering singularity and convergence issues. Instead, I will pursue a more practical and parsimonious approach to model specification. To inform the final decision regarding the appropriate family and structure of the model, I will conduct a series of diagnostic tests and generate visualizations to better understand the data. These preliminary analyses will provide essential insights into the response distribution, variability, and other relevant characteristics, ensuring that the chosen model is both robust and well-suited to the problem at hand.\nFirstly, I will try to visualize the different relations between the variables of interest.\n\n## Criterion for gold metals\nhigh_medal &lt;- mydata %&gt;% filter(n &gt; 20)\n\n\nggplot(mydata, aes(x = log_pop, y = log_gdp)) +\n  geom_point(size = 3, aes(color = factor(wealthy_class)), alpha = 0.7) +  # Points colored by wealthy_class\n  geom_smooth(aes(group = factor(wealthy_class), color = factor(wealthy_class)), \n              method = \"lm\", se = TRUE, formula = 'y ~ x') + # Regression line for each group\n  ggalt::geom_encircle(data = high_medal, aes(x = log_pop, y = log_gdp), color = \"black\", size = 1)+\n  labs(\n    title = \"Interaction between Log Population and Log GDP\",\n    x = \"Logarithm of Population (log_pop)\",\n    y = \"Logarithm of GDP (log_gdp)\",\n    color = \"Wealthy Class\") +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.title = element_text(face = \"bold\", size = 16),\n    axis.text = element_text(size = 12),\n    plot.title = element_text(face = \"bold\", size = 18, hjust = 0.5),\n    legend.position = \"top\",\n    legend.title = element_text(size = 14),\n    legend.text = element_text(size = 12))\n\n\n\n\n\n\n\n\nThe graph illustrates the interaction between the logarithm of population (log_pop) and the logarithm of GDP (log_gdp) across four wealth categories (“Wealthy Class”). A positive relationship is observed between population and GDP for all groups, with regression lines indicating that wealthier classes (e.g., classes 3 and 4) exhibit higher GDP levels for a given population size compared to less wealthy classes (e.g., classes 1 and 2). The encircled points represent countries with more than 20 medals, highlighting that high athletic success is generally associated with nations that have larger populations and higher GDPs. This suggests that economic resources and population size play a significant role in achieving athletic success, as wealthier and more populous nations tend to dominate medal counts. The graph further underscores disparities in economic capacity and their potential influence on global sports performance.\n\n# Scatter plot with color indicating the number of gold medals\nggplot(mydata, aes(x = log_pop, y = log_gdp, color = n)) +\n  geom_point(size = 3, alpha = 0.7) +\n  scale_color_gradient(low = \"blue\", high = \"red\") +\n  labs(\n    title = \"Effect of Log Population and Log GDP on Number of Gold Medals\",\n    x = \"Logarithm of Population (log_pop)\",\n    y = \"Logarithm of GDP (log_gdp)\",\n    color = \"Gold Medals\"\n  ) +\n theme_minimal(base_size = 14) +\n theme(\n    axis.title = element_text(face = \"bold\", size = 16),\n    axis.text = element_text(size = 12),\n    plot.title = element_text(face = \"bold\", size = 18, hjust = 0.5),\n    legend.position = \"top\",\n    legend.title = element_text(size = 14),\n    legend.text = element_text(size = 12))\n\n\n\n\n\n\n\n\nThe scatter plot depicts the relationship between the logarithm of population (log_pop) and the logarithm of GDP (log_gdp), with the color intensity of each point representing the number of gold medals won by a country. A positive correlation is observed between population and GDP, as countries with larger populations tend to have higher GDPs. Additionally, countries that have won more gold medals are represented by red-shaded points, predominantly located in regions of high log_pop and log_gdp. This trend suggests that nations with both substantial populations and strong economic capacity are more likely to achieve greater success in terms of gold medal counts. The gradient from blue (fewer medals) to red (more medals) further highlights the influence of economic and demographic factors on athletic performance at an international level.\nSome additional graphs indicating this correlation are:\n\n#| warning: false\n#| message: false\np1 &lt;- ggplot(mydata, aes(x = log_gdp, y = n,\n                         color = factor(wealthy_class),\n                         group = wealthy_class)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(\n    method = \"glm\",\n    formula = y ~ x,\n    method.args = list(family = quasipoisson),\n    se = FALSE\n  ) +\n  labs(\n    title = \"Gold Medals vs Log GDP by Wealth Class\",\n    x = \"Log GDP\",\n    y = \"Number of Gold Medals\",\n    color = \"Wealth Class\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.title = element_text(face = \"bold\", size = 16),\n    axis.text = element_text(size = 12),\n    plot.title = element_text(face = \"bold\", size = 18, hjust = 0.5),\n    legend.position = \"top\",\n    legend.title = element_text(size = 14),\n    legend.text = element_text(size = 12)\n  )\n\n\np2 &lt;- ggplot(mydata, aes(x = log_pop, y = n,\n                         color = factor(wealthy_class),\n                         group = wealthy_class)) +\n  geom_point(alpha = 0.5) +\n  geom_smooth(\n    method = \"glm\",\n    formula = y ~ x,\n    method.args = list(family = quasipoisson),\n    se = FALSE\n  ) +\n  labs(\n    title = \"Gold Medals vs Log Population by Wealth Class\",\n    x = \"Log Population\",\n    y = \"Number of Gold Medals\",\n    color = \"Wealth Class\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    axis.title = element_text(face = \"bold\", size = 16),\n    axis.text = element_text(size = 12),\n    plot.title = element_text(face = \"bold\", size = 18, hjust = 0.5),\n    legend.position = \"top\",\n    legend.title = element_text(size = 14),\n    legend.text = element_text(size = 12)\n  )\n\n\np3 &lt;- ggplot(mydata, aes(x = centered_log_pop, y = log_gdp, colour = team)) +\n  geom_point(alpha = 0.5) +\n  stat_ellipse(aes(fill = team), geom = \"polygon\", alpha = 0.2) +\n  labs(\n    title = \"Elliptical Clusters of GDP and Population by Team\",\n    x = \"Centered Log(Population)\",\n    y = \"Log(GDP)\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 18, hjust = 0.5),\n    axis.title = element_text(face = \"bold\", size = 16),\n    axis.text = element_text(size = 12),\n    legend.position = \"none\"\n  )\n\n(p1 | p2) / p3 +\n  plot_annotation(\n    title = \"Economic Indicators and Olympic Gold Medals\",\n    theme = theme(\n      plot.title = element_text(face = \"bold\", size = 20, hjust = 0.5)\n    )\n  )\n\n\n\n\n\n\n\n\nBellow I will create an interactive 3D scatter plot capturing the effect of population and GDP on the number of gold medals:\n\n# Fit the Negative Binomial GLM model\nmodel &lt;- lm(log_n ~ log_pop + log_gdp, data = mydata)\n\n# Create a grid of values for log_pop and log_gdp_perC to calculate the predicted surface\ngrid_data &lt;- expand.grid(\n  log_pop = seq(min(mydata$log_pop), max(mydata$log_pop), length.out = 50),\n  log_gdp = seq(min(mydata$log_gdp), max(mydata$log_gdp), length.out = 50)\n)\n\n# Add predictions for the grid using the Negative Binomial model\ngrid_data$n &lt;- predict(model, newdata = grid_data, type = \"response\")\n\n\n# 3D Scatter plot with linear surface\nplot_ly() %&gt;%\n  # Add scatter plot points\n  add_markers(\n    data = mydata,\n    x = ~log_pop,\n    y = ~log_gdp,\n    z = ~log_n,\n    marker = list(\n      size = ~log_pop * 3,  # Dynamically adjust size based on log population\n      color = ~log_gdp,  # Color by log GDP\n      colorscale = \"Plasma\",\n      opacity = 0.7,\n      line = list(width = 1, color = 'black')\n    ),\n    hoverinfo = \"text\",\n    text = ~paste(\n      \"Country: \", team, \"&lt;br&gt;\",\n      \"Log Population: \", round(log_pop, 2), \"&lt;br&gt;\",\n      \"Log GDP: \", round(log_gdp, 2), \"&lt;br&gt;\",\n      \"Gold Medals: \", n, \"&lt;br&gt;\"\n    )\n  ) %&gt;%\n  # Add linear surface\n  add_surface(\n    x = unique(grid_data$log_pop),\n    y = unique(grid_data$log_gdp),\n    z = matrix(grid_data$n, nrow = 50, ncol = 50),\n    opacity = 0.5,\n    colorscale = list(c(0, 1), c(\"lightblue\", \"blue\"))\n  ) %&gt;%\n  layout(\n    title = \"Effect of Population and GDP on Gold Medals with Linear Surface\",\n    scene = list(\n      xaxis = list(title = \"Log Population\"),\n      yaxis = list(title = \"Log GDP\"),\n      zaxis = list(title = \"Gold Medals\")\n    )\n  )\n\n\n\n\n\nThe provided plot explores the relationship between a country’s population (log-transformed), GDP (log-transformed), and the number of gold medals won at the Olympics, with a linear surface included for reference. While the linear plane provides a simplified approximation, the distribution of points reveals that the relationship is not strictly linear, as evident from the variability and clustering of data points around the surface, Moreover it seem like there is heteroscedasticity within the data. This suggests that the impact of economic and demographic factors on Olympic success is influenced by non-linear dynamics, and of course that there are hidden structures and variables, such as cultural emphasis on sports, investment in athletic programs, and historical performance trends. The use of log-transformed variables aids in managing the wide disparities in GDP and population among countries, allowing for a more nuanced interpretation of the observed patterns.\nFor the sake of completeness, below I provide an animated version of the same graph, which displays the data over time. This animation allows for a clearer visualization of the evolving structures across different years.\n\nplot_ly(\n  mydata,\n  x = ~log_pop,\n  y = ~log_gdp,\n  z = ~log_n,\n  frame = ~year,  # Animate by year\n  type = \"scatter3d\",\n  mode = \"markers\",\n  marker = list(\n    size = ~log_pop * 3,  # Dynamically adjust size based on log population\n    color = ~log_gdp,  # Color by log GDP\n    colorscale = \"Plasma\",  # Plasma color scale for a vibrant effect\n    colorbar = list(title = \"Log GDP\"),  # Color scale title\n    opacity = 0.7,\n    symbol = 'circle',\n    line = list(width = 1, color = 'black')\n  ),\n  hoverinfo = \"text\",\n  text = ~paste(\n    \"Country: \", team, \"&lt;br&gt;\",\n    \"Year: \", year, \"&lt;br&gt;\",\n    \"Log Population: \", round(log_pop, 2), \"&lt;br&gt;\",\n    \"Log GDP: \", round(log_gdp, 2), \"&lt;br&gt;\",\n    \"Gold Medals: \", n, \"&lt;br&gt;\",\n    \"Rank by Medals: \", rank(-n)\n  )\n) %&gt;%\n  layout(\n    title = \"3D Effect of Log Population and Log GDP on Gold Medals (Animated by Year)\",\n    scene = list(\n      xaxis = list(\n        title = \"Log Population\",\n        gridcolor = \"lightgray\",\n        showbackground = TRUE,\n        backgroundcolor = \"rgb(240, 240, 240)\",\n        zeroline = TRUE\n      ),\n      yaxis = list(\n        title = \"Log GDP\",\n        gridcolor = \"lightgray\",\n        showbackground = TRUE,\n        backgroundcolor = \"rgb(240, 240, 240)\",\n        zeroline = TRUE\n      ),\n      zaxis = list(\n        title = \"Gold Medals\",\n        gridcolor = \"lightgray\",\n        showbackground = TRUE,\n        backgroundcolor = \"rgb(240, 240, 240)\",\n        zeroline = TRUE\n      )\n    ),\n    margin = list(l = 50, r = 50, b = 50, t = 100),\n    paper_bgcolor = \"rgb(255, 255, 255)\",\n    plot_bgcolor = \"rgb(240, 240, 240)\",\n    showlegend = FALSE,\n    updatemenus = list(\n      list(\n        type = \"buttons\",\n        x = 0.1,\n        y = 0.95,\n        buttons = list(\n          list(\n            method = \"animate\",\n            args = list(NULL, list(frame = list(duration = 500, redraw = TRUE), fromcurrent = TRUE)),\n            label = \"Play\"\n          ),\n          list(\n            method = \"animate\",\n            args = list(NULL, list(frame = list(duration = 0, redraw = TRUE), mode = \"immediate\", transition = list(duration = 0))),\n            label = \"Pause\"\n          )\n        )\n      )\n    )\n  )\n\n\n\n\n\nAgain the interpretation is similar with similar structure across the years. Bellow I will provide the same plot with the regression surface from the first analysis (for comparison reasons)\n\n# Fit the Negative Binomial GLM model\nnb_model &lt;- glm.nb(n ~ log_pop + log_gdp_perC, data = mydata)\n\n# Create a grid of values for log_pop and log_gdp_perC to calculate the predicted surface\ngrid_data_nb &lt;- expand.grid(\n  log_pop = seq(min(mydata$log_pop), max(mydata$log_pop), length.out = 50),\n  log_gdp_perC = seq(min(mydata$log_gdp_perC), max(mydata$log_gdp_perC), length.out = 50)\n)\n\n# Add predictions for the grid using the Negative Binomial model\ngrid_data_nb$n &lt;- predict(nb_model, newdata = grid_data_nb, type = \"response\")\n\n# 3D scatter plot with the Negative Binomial model surface\nplot_ly() %&gt;%\n  # Add scatter plot points\n  add_markers(\n    data = mydata,\n    x = ~log_pop,\n    y = ~log_gdp_perC,\n    z = ~n,\n    marker = list(\n      size = ~log_pop * 3,  # Dynamically adjust size based on log population\n      color = ~log_gdp_perC,  # Color by log GDP per capita\n      colorscale = \"Plasma\",  # Plasma color scale for a vibrant effect\n      opacity = 0.7,  # Set opacity for better clarity\n      line = list(width = 1, color = 'black')  # Add black outline to markers\n    ),\n    hoverinfo = \"text\",\n    text = ~paste(\n      \"Country: \", team, \"&lt;br&gt;\",\n      \"Log Population: \", round(log_pop, 2), \"&lt;br&gt;\",\n      \"Log GDP per Capita: \", round(log_gdp_perC, 2), \"&lt;br&gt;\",\n      \"Gold Medals: \", n, \"&lt;br&gt;\"\n    )\n  ) %&gt;%\n  # Add surface based on the Negative Binomial model predictions\n  add_surface(\n    x = unique(grid_data_nb$log_pop),\n    y = unique(grid_data_nb$log_gdp_perC),\n    z = matrix(grid_data_nb$n, nrow = 50, ncol = 50),\n    opacity = 0.5,  # Set surface opacity\n    colorscale = list(c(0, 1), c(\"lightgreen\", \"green\"))  # Color scale for the surface\n  ) %&gt;%\n  layout(\n    title = \"Effect of Log Population and Log GDP per Capita on Gold Medals (Negative Binomial Model)\",\n    scene = list(\n      xaxis = list(title = \"Log Population\"),\n      yaxis = list(title = \"Log GDP per Capita\"),\n      zaxis = list(\n        title = \"Gold Medals\",\n        range = c(0, 200)  # Restrict Z-axis to 0-200 for better visualization\n      )\n    )\n  )\n\n\n\n\n\nThe graph demonstrates a reasonably good fit of the model from the initial analysis. Based on these illustrations, I have decided to include the following fixed effects in my new model: the logarithm of population, the logarithm of GDP, the centered year, and the interaction between the natural spline terms of the logarithms of population and the logarithm of GDP with 3 degrees of freedom, each. Additionally, the intercept will vary by country (team). This model setup is designed to capture both linear and non-linear relationships within the data. To determine the appropriate family (Poisson or negative binomial to account for overdispersion), I will now proceed with a test for overdispersion.\n\nm &lt;- glmmTMB(\n  n ~ 1 + log_pop + log_gdp + ns(log_pop, df = 3):ns(log_gdp, df = 3) + centered_year + (1|team),\n  data = mydata,\n family = poisson(link = \"log\")\n )\n\noverdisp_fun &lt;- function(m) {\n    rdf &lt;- df.residual(m)\n    rp &lt;- residuals(m,type=\"pearson\")\n    Pearson.chisq &lt;- sum(rp^2)\n    prat &lt;- Pearson.chisq/rdf\n    pval &lt;- pchisq(Pearson.chisq, df=rdf, lower.tail=FALSE)\n    c(chisq=Pearson.chisq,ratio=prat,rdf=rdf,p_value=pval)\n}\noverdisp_fun(m)\n\n       chisq        ratio          rdf      p_value \n1.007970e+03 1.912656e+00 5.270000e+02 1.571927e-32 \n\n\nTo assess the adequacy of the Poisson regression model fitted using the glmmTMB package, we evaluated overdispersion using the Pearson chi-squared statistic. The computed Pearson chi-squared value was 1007.97, with 527 degrees of freedom, resulting in a dispersion ratio of 1.91. A dispersion ratio greater than 1 indicates the presence of overdispersion, suggesting that the variability in the data exceeds what is expected under the Poisson distribution. The associated p-value was extremely small (p&lt; 2×10−16), further confirming that overdispersion is statistically significant. These results suggest that the Poisson model may not adequately capture the observed data’s variability, and alternative models, such as those accounting for overdispersion (e.g., Negative Binomial models), should be considered.\nTo further investigate the characteristics of the data, I will run a simulation to assess the presence of an unexpectedly high number of zeros. This will help determine whether a zero-inflation model is necessary to properly account for an excess of zero counts in the data. The results of this simulation will guide the decision on whether incorporating zero inflation is warranted in the modeling process.\n\nset.seed(123)\n\nmodel &lt;- glmmTMB(\n  n ~ 1 + log_pop + log_gdp + ns(log_pop, df = 3):ns(log_gdp, df = 3) + centered_year + (1|team),\n  ziformula = ~ 0,\n  dispformula = ~ 1,\n  data = mydata,\n family = nbinom12(link = \"log\")\n )\n\n# Simulate new responses from the negative binomial model\nsim_vals &lt;- simulate(model, nsim = 1000)\n# Calculate the number of zeros in each simulation and in the observed data\nzeros_sim &lt;- colSums(sim_vals == 0)\nzeros_obs &lt;- sum(mydata$n == 0)\n\n# Create a histogram of the number of zeros in the simulated data\nhist(zeros_sim, breaks = 30, main = \"Distribution of Simulated Zeros\",\n     xlab = \"Number of Zeros\", col = \"skyblue\", border = \"black\",\n     xlim = range(c(zeros_sim, zeros_obs), na.rm = TRUE), \n     freq = FALSE)\n\n# Add a vertical line representing the observed number of zeros\nabline(v = zeros_obs, col = \"red\", lwd = 2, lty = 2)\n\n# Overlay the normal distribution curve for reference\ncurve(dnorm(x, mean = mean(zeros_sim), sd = sd(zeros_sim)), \n      add = TRUE, col = \"darkgreen\", lwd = 2)\n\n\n\n\n\n\n\n# Calculate p-value based on simulation results\np_value &lt;- mean(zeros_sim &gt;= zeros_obs)\ncat(\"P-value from simulation: \", p_value, \"\\n\")\n\nP-value from simulation:  0.626 \n\n# Perform DHARMa test for zero-inflation\nsimulation_output &lt;- simulateResiduals(fittedModel = model)\ndh_test &lt;- testZeroInflation(simulation_output)\n\n\n\n\n\n\n\ncat(\"P-value from DHARMa test: \", dh_test$p.value, \"\\n\")\n\nP-value from DHARMa test:  0.776 \n\n\nBased on the exploratory analysis and data characteristics, I have determined that a zero-inflation model is not necessary for this dataset. Consequently, I will employ a negative binomial regression mixed model. This choice is motivated by the following considerations:\n\nCount Data with Overdispersion: The dependent variable represents count data, and preliminary analysis indicates the presence of overdispersion (variance exceeding the mean), making the negative binomial model more appropriate than a Poisson model.\nLack of Zero Inflation: An inspection of the response variable distribution shows no substantial excess of zeros that would warrant the use of a zero-inflated model.\nIncorporating Random Effects: The hierarchical nature of the data, with observations nested within groups (e.g., teams or countries), makes a sensible decision the inclusion of random effects to account for group-level variability.\n\nThe negative binomial regression mixed model will enable a robust analysis of the relationship between predictors and the response variable while appropriately addressing the overdispersion and hierarchical structure of the data.\n\n\ne) Model Fit and Diagnostics\n\n# Model fit\nmodel &lt;- glmmTMB(\n  n ~ 1 + log_pop + log_gdp + ns(log_pop, df = 3):ns(log_gdp, df = 3) + centered_year + (1|team),\n  ziformula = ~ 0,\n  dispformula = ~1,\n  data = mydata,\n family = nbinom1(link = \"log\")\n )\n\nsummary(model)\n\n Family: nbinom1  ( log )\nFormula:          \nn ~ 1 + log_pop + log_gdp + ns(log_pop, df = 3):ns(log_gdp, df = 3) +  \n    centered_year + (1 | team)\nData: mydata\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n   1996.3    2060.7    -983.1    1966.3       526 \n\nRandom effects:\n\nConditional model:\n Groups Name        Variance Std.Dev.\n team   (Intercept) 1.225    1.107   \nNumber of obs: 541, groups:  team, 109\n\nDispersion parameter for nbinom1 family ():  3.5 \n\nConditional model:\n                                           Estimate Std. Error z value Pr(&gt;|z|)\n(Intercept)                               -3.424196   1.030880  -3.322 0.000895\nlog_pop                                   -0.940909   0.571611  -1.646 0.099750\nlog_gdp                                   -0.446034   0.770755  -0.579 0.562793\ncentered_year                             -0.022103   0.007238  -3.054 0.002261\nns(log_pop, df = 3)1:ns(log_gdp, df = 3)1  3.725862   3.816835   0.976 0.328983\nns(log_pop, df = 3)2:ns(log_gdp, df = 3)1 12.902521   8.743490   1.476 0.140032\nns(log_pop, df = 3)3:ns(log_gdp, df = 3)1  8.522550   5.297929   1.609 0.107691\nns(log_pop, df = 3)1:ns(log_gdp, df = 3)2 16.498703   8.073483   2.044 0.040996\nns(log_pop, df = 3)2:ns(log_gdp, df = 3)2 41.255653  22.997115   1.794 0.072821\nns(log_pop, df = 3)3:ns(log_gdp, df = 3)2 15.200190  12.141897   1.252 0.210614\nns(log_pop, df = 3)1:ns(log_gdp, df = 3)3  8.517357   6.975405   1.221 0.222065\nns(log_pop, df = 3)2:ns(log_gdp, df = 3)3 26.126432  14.718697   1.775 0.075890\nns(log_pop, df = 3)3:ns(log_gdp, df = 3)3  5.381917   6.622150   0.813 0.416382\n                                             \n(Intercept)                               ***\nlog_pop                                   .  \nlog_gdp                                      \ncentered_year                             ** \nns(log_pop, df = 3)1:ns(log_gdp, df = 3)1    \nns(log_pop, df = 3)2:ns(log_gdp, df = 3)1    \nns(log_pop, df = 3)3:ns(log_gdp, df = 3)1    \nns(log_pop, df = 3)1:ns(log_gdp, df = 3)2 *  \nns(log_pop, df = 3)2:ns(log_gdp, df = 3)2 .  \nns(log_pop, df = 3)3:ns(log_gdp, df = 3)2    \nns(log_pop, df = 3)1:ns(log_gdp, df = 3)3    \nns(log_pop, df = 3)2:ns(log_gdp, df = 3)3 .  \nns(log_pop, df = 3)3:ns(log_gdp, df = 3)3    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\n\n# Check for singularity\n# vc &lt;- VarCorr(model)$cond$team; eigen(vc) \n# performance::check_model(model)\n# Create a DHARMa residuals object\nresiduals_dharma &lt;- simulateResiduals(model)\n# Plot the residuals\nplot(residuals_dharma)\n\n\n\n\n\n\n\n# Extract fitted values and residuals\nfitted_values &lt;- fitted(model)\nresiduals &lt;- residuals(model)\n\n# Plot residuals vs fitted values\nggplot(data.frame(fitted = fitted_values, residuals = residuals), aes(x = fitted, y = residuals)) +\n  geom_point() +\n  geom_smooth(method = \"loess\", color = \"red\", formula = 'y ~ x') +\n  labs(title = \"Residuals vs Fitted Values\", x = \"Fitted Values\", y = \"Residuals\") +\n  theme_minimal()\n\n\n\n\n\n\n\nr2.corr.mer &lt;- function(m) {\n   lmfit &lt;-  lm(model.response(model.frame(m)) ~ fitted(m))\n   summary(lmfit)$r.squared\n}\n\ncat(\"R^2 = \", r2.corr.mer(model), \"\\n\")\n\nR^2 =  0.9080412 \n\nperformance::r2(model)\n\n# R2 for Mixed Models\n\n  Conditional R2: 0.886\n     Marginal R2: 0.503\n\n\nThe diagnostic assessment of the fitted mixed-effects model using DHARMa residual diagnostics reveals no significant deviations from model assumptions. The QQ plot of residuals indicates no substantial departures from normality, with p-values for the Kolmogorov-Smirnov (KS) test, dispersion test, and outlier test all being nonsignificant (p &gt; 0.1). Similarly, the residuals versus predicted values plot shows no discernible patterns, suggesting homoscedasticity. The conditional R² value for the model is 0.886, indicating that the full model (fixed and random effects combined) explains approximately 88.6% of the variance. The marginal R² value of 0.503 reflects that fixed effects alone account for 50.3% of the variance. The calculated R² using the auxiliary r2.corr.mer function is 0.908, corroborating the high explanatory power of the model. These results suggest the model provides a robust fit to the data without significant violations of underlying assumptions.\n\n\nf) Visualizing the Results\n\n# Extract fixed effects with confidence intervals\nfixed_effects &lt;- broom.mixed::tidy(model, effects = \"fixed\", conf.int = TRUE)\n\n\ndwplot(fixed_effects) +\n  theme_minimal() +\n  labs(\n    title = \"Fixed Effects Coefficients\",\n    subtitle = \"Including 95% Confidence Intervals\",\n    x = \"Coefficient Estimate\",\n    y = \"Predictors\"\n  ) +\n  geom_vline(xintercept = 0, linetype = \"dashed\", color = \"red\") +\n  theme(\n    axis.text = element_text(size = 12, color = \"black\"),\n    axis.title = element_text(size = 14, face = \"bold\"),\n    plot.title = element_text(size = 16, face = \"bold\"),\n    plot.subtitle = element_text(size = 12, face = \"italic\"),\n    panel.grid.major = element_line(color = \"gray\", linetype = \"dotted\"),\n    panel.grid.minor = element_blank(),\n    panel.border = element_rect(color = \"black\", fill = NA, linewidth = 0.8)  # Updated size to linewidth\n  ) +\n  scale_color_manual(values = c(\"blue\", \"red\"))  # Customize the color scheme for better visualization\n\n\n\n\n\n\n\n\nThe plot above visualizes the fixed-effect coefficients from a regression model, along with their 95% confidence intervals. The predictors include log-transformed population size (log_pop), log-transformed GDP (log_gdp), a centered measure of time (centered_year), and interaction terms involving natural splines of log_pop and log_gdp. While the coefficients for log_pop, log_gdp, and centered_year are relatively small with tight confidence intervals, the interaction terms involving spline components exhibit larger coefficient estimates with wider confidence intervals, indicating greater variability and potential non-linear relationships. Notably, many confidence intervals overlap the reference line at zero, suggesting that some predictors may not have statistically significant effects. This highlights the complex interplay between predictors and the importance of assessing interaction effects in modeling.\n\n# Generate predictions for the interaction effect\neffect_data &lt;- ggpredict(model, terms = c(\"log_pop\", \"log_gdp\"))\n\n# Effects plot\nggplot(effect_data, aes(x = x, y = predicted, color = group)) +\n  geom_line() +\n  theme_minimal() +\n  labs(title = \"Effects of Population and GDP Interaction\",\n       x = \"Log Population\",\n       y = \"(log-scale) Predicted Count (n)\",\n       color = \"Log GDP\")+\n  theme_minimal(base_size = 14) +\n theme(\n    axis.title = element_text(face = \"bold\", size = 16),\n    axis.text = element_text(size = 12),\n    plot.title = element_text(face = \"bold\", size = 18, hjust = 0.5),\n    legend.position = \"top\",\n    legend.title = element_text(size = 14),\n    legend.text = element_text(size = 12))\n\n\n\n\n\n\n\n\nThe plot illustrates the interaction effects between log-transformed population size (log_pop) and log-transformed GDP (log_gdp) on the predicted response variable, measured on a log scale. The curves represent predictions for different levels of log_gdp (2.56, 4.5, and 6.44), showing how the predicted count varies with changes in population size. At lower values of log_pop, the predicted counts are relatively small across all GDP levels. As log_pop increases, the predicted response rises significantly, especially for higher GDP levels (e.g., log_gdp = 6.44), demonstrating a synergistic interaction. However, the trajectories differ; while predictions for the highest GDP level continue to rise at higher population sizes, predictions for lower GDP levels plateau or decline. This suggests a complex interplay between economic and population factors in shaping the outcome."
  },
  {
    "objectID": "Project_4.html#analysis-of-toenail-dataset-from-hsaur3-package",
    "href": "Project_4.html#analysis-of-toenail-dataset-from-hsaur3-package",
    "title": "Project 4",
    "section": "2. Analysis of toenail Dataset from HSAUR3 Package",
    "text": "2. Analysis of toenail Dataset from HSAUR3 Package\n\nDescription of the Dataset\nThe Toenail Infection Dataset consists of data from a clinical trial designed to compare the effectiveness of two oral antifungal treatments, itraconazole and terbinafine, for treating toenail infections caused by dermatophytes (onychomycosis). The dataset includes 1,908 observations across 378 patients, each uniquely identified by a patientID. The key variables include outcome, which represents the degree of separation between the nail plate and the nail bed (onycholysis), and is categorized into moderate or severe versus none or mild; treatment, a factor indicating the administered medication (itraconazole or terbinafine); time, the actual visit time in months; and visit, indicating the number of the visit. The study followed patients over seven visits, initially scheduled at weeks 0, 4, 8, 12, 24, 36, and 48, although the timing of actual visits varied. The data is unbalanced, as not all patients attended all seven visits, reflecting real-world deviations from the planned schedule. This dataset provides valuable insights into the treatment’s impact over time on the severity of onycholysis in toenail infection patients.\n\n# Load the toenail data\ndata(\"toenail\")\n\nmydata &lt;- toenail\nmydata &lt;- mydata %&gt;%\n  mutate(outcome_binary = ifelse(outcome %in% c(\"none or mild\"), 0, 1))\nmydata$patientID &lt;- as.factor(mydata$patientID)\n\n\nhead(mydata)\n\n  patientID            outcome   treatment       time visit outcome_binary\n1         1 moderate or severe terbinafine  0.0000000     1              1\n2         1 moderate or severe terbinafine  0.8571429     2              1\n3         1 moderate or severe terbinafine  3.5357140     3              1\n4         1       none or mild terbinafine  4.5357140     4              0\n5         1       none or mild terbinafine  7.5357140     5              0\n6         1       none or mild terbinafine 10.0357100     6              0\n\n# ?toenail\n\n\n\na) Maximal Model Specification for Predicting the Sensitivity Outcome with Fixed and Random Effects\nTo create a maximal model specification for predicting the binary sensitivity outcome (outcome_binary) in the toenail data, we’ll need to account for both fixed and random effects. Since this is a repeated measures dataset (patients have multiple visits), a mixed-effects model is appropriate, where we include both patient-level random effects and treatment and time as fixed effects.\n\n\nMaximal Model Specification\n\nFixed Effects:\n\nTreatment: The type of treatment (terbinafine, itraconazole) can influence the outcome, so it will be a fixed effect.\nTime: Time is a continuous predictor, representing the progression of treatment. We may expect a nonlinear relationship, so this might be modeled using natural splines or polynomials.\nVisit: The visit number could also be included as a fixed effect, especially if it interacts with treatment or time.\n\nRandom Effects:\n\nRandom Intercept for Patient: Each patient could have a different baseline level of the outcome, so we include a random intercept for patientID.\nRandom Slope for Time within Patient: It’s likely that the effect of time (or treatment progression) varies between patients. Hence, we may model a random slope for time within patients.\n\n\nMoreover, we could include different interactions:\n\nTreatment x Time Interaction: The effect of time may differ by treatment, so an interaction term between treatment and time is included.\nTreatment x Visit Interaction: The effect of treatment may vary across different visits.\n\nGiven the binary nature of the response variable is completely sensible to use a logistic regression mixed model from the binomial family.\n\n\nb and c)\nInitially, I will not employ the maximal model. Instead, I plan to visualize the data to gain insights into its underlying structure. This exploratory step will inform the development of the final model by helping to identify patterns and relationships within the data.\n\nmydata %&gt;%\n  group_by(treatment, visit) %&gt;%\n  summarise(success_rate = mean(outcome_binary), .groups = \"drop\") %&gt;%  # Ungroup the data\n  ggplot(aes(x = visit, y = success_rate, fill = treatment)) +\n  geom_bar(stat = \"identity\", position = \"dodge\") +\n  labs(title = \"Proportion of Success by Treatment and Visit\", \n       x = \"Visit\", \n       y = \"Proportion of Success\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nSuccess by Treatment and Visit (Bar Chart): This plot compares the proportion of successful outcomes between two treatments, itraconazole and terbinafine, over a series of visits. At visit 2, itraconazole demonstrates a marginally higher proportion of success compared to terbinafine, with the gap narrowing by visit 4. By visits 6 and beyond, both treatments show a decline in success rates, with little distinction between the two treatments. This trend suggests that the efficacy of both treatments may diminish over time, potentially indicating a need for further investigation into long-term effectiveness or other influencing factors.\n\n# Facet grid to show outcome_binary by treatment and time\nggplot(mydata, aes(x = time, y = outcome_binary)) +\n  geom_point(aes(color = treatment)) + \ngeom_smooth(method = \"gam\", formula = y ~ s(x), aes(group = treatment), se = FALSE)+\n  facet_grid(treatment ~ visit) + # Facet by treatment and visit\n  labs(title = \"Outcome by Treatment and Visit\",\n       x = \"Time\",\n       y = \"Binary Outcome (0 = None/Mild, 1 = Moderate/Severe)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nOutcome by Treatment and Visit (Scatter Plot Matrix): This figure provides a detailed temporal view of binary outcomes (0 = None/Mild, 1 = Moderate/Severe) across time points and visits for both itraconazole and terbinafine. The data reveals a higher prevalence of moderate/severe outcomes (outcome = 1) in the itraconazole group, particularly at earlier visits, with variability decreasing over time. In contrast, terbinafine shows a more consistent distribution of mild outcomes (outcome = 0). The temporal clustering indicates differing response patterns to the two treatments, with itraconazole exhibiting greater variability in efficacy during earlier phases of treatment.\n\n# Heatmap of outcome_binary by time and treatment\nggplot(mydata, aes(x = time, y = treatment, fill = outcome_binary)) +\n  geom_tile() +\n  scale_fill_viridis(option = \"C\") +\n  labs(title = \"Heatmap of Outcome by Treatment and Time\",\n       x = \"Time\",\n       y = \"Treatment\",\n       fill = \"Binary Outcome (0 = None/Mild, 1 = Moderate/Severe)\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nHeatmap of Outcome by Treatment and Time: This heatmap visualizes the distribution of binary outcomes (0 = None/Mild, 1 = Moderate/Severe) across time for both treatments. Terbinafine predominantly shows outcomes concentrated in the lower range (None/Mild), indicating better overall efficacy. Itraconazole exhibits more frequent occurrences of moderate/severe outcomes, represented by warmer colors (yellow). The temporal and treatment-specific clustering suggests that terbinafine consistently maintains better outcomes over time, while itraconazole shows more fluctuation and less favorable results in terms of severity.\nThe analysis reveals clear correlations between treatment type, time, and outcome severity. Terbinafine consistently shows better efficacy, with a higher proportion of mild outcomes (binary outcome = 0) over time, as reflected inthe plots. In contrast, itraconazole exhibits a higher frequency of moderate to severe outcomes (binary outcome = 1), particularly at earlier visits, indicating less consistent performance. The bar chart supports this trend, showing a slight early advantage for itraconazole in success rates at visit 2, but this diminishes over time, aligning with terbinafine’s more stable efficacy. These findings indicate a strong negative correlation between time and treatment efficacy for both drugs, but the decline is more pronounced for itraconazole. Overall, terbinafine demonstrates a more robust and sustained correlation with favorable outcomes, suggesting it is the superior treatment option.\nAfter conducting an extensive graphical analysis, a logistic regression mixed model was chosen for the analysis. The model will use a logit link function to capture the binary nature of the response variable. The fixed effects in the model will include time, treatment, and their interaction (time × treatment), allowing for the assessment of how the treatment effect evolves over time. Additionally, a random intercept will be included to account for variability among individual patients, identified by patientID.\n\n\nd) Model Fit and Diagnostics\n\n# Model fit\nmodel &lt;- glmer(outcome_binary ~ time*treatment + (1 | patientID), \n               data = mydata, \n               family = binomial(link = \"logit\"))\nsummary(model)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: outcome_binary ~ time * treatment + (1 | patientID)\n   Data: mydata\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n   1265.6    1293.4    -627.8    1255.6      1903 \n\nScaled residuals: \n   Min     1Q Median     3Q    Max \n-3.290 -0.149 -0.071 -0.006 47.215 \n\nRandom effects:\n Groups    Name        Variance Std.Dev.\n patientID (Intercept) 20.76    4.557   \nNumber of obs: 1908, groups:  patientID, 294\n\nFixed effects:\n                          Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)               -2.50986    0.76394  -3.285  0.00102 ** \ntime                      -0.39973    0.04679  -8.543  &lt; 2e-16 ***\ntreatmentterbinafine      -0.30483    0.68708  -0.444  0.65729    \ntime:treatmentterbinafine -0.13714    0.06949  -1.973  0.04846 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) time   trtmnt\ntime         0.130              \ntrtmnttrbnf -0.374  0.220       \ntm:trtmnttr  0.181 -0.541 -0.265\n\n#isSingular(model)\n\n\n# Check for singularity\n# vc &lt;- VarCorr(model); eigen(vc) \n# performance::check_model(model)\n# Create a DHARMa residuals object\nresiduals_dharma &lt;- simulateResiduals(model)\n# Plot the residuals\nplot(residuals_dharma)\n\n\n\n\n\n\n\n\nThe DHARMa residual diagnostics provide a comprehensive assessment of model fit by comparing observed and expected residual distributions and evaluating potential patterns in the residuals. The QQ plot (left panel) reveals a slight deviation from the expected distribution, supported by a significant Kolmogorov-Smirnov (KS) test (p = 0.04303). However, given the asymptotic nature of these results and the visual inspection of the QQ plot, the deviations appear to be within acceptable limits.\nThe dispersion and outlier tests indicate no significant departures from the expected distribution, with p-values of 0.072 and 0.51806, respectively, suggesting no evidence of overdispersion or the presence of influential outliers. The residuals vs. predicted values plot (right panel) shows some quantile deviations, highlighted by the red curves, which may suggest a potential non-linear relationship. The combined adjusted quantile test is significant, indicating possible model misspecifications. However, no indications of heteroscedasticity are observed.\nThe conditional R2 value of 0.884 reflects the variance explained by both fixed and random effects, while the marginal R2 value of 0.154 highlights the contribution of fixed effects alone.\nIn summary, while minor issues related to non-linearity and residual deviations are present, they are deemed acceptable for the purposes of this analysis.\n\n\ne) Visualizing the Results\n\nsjPlot::plot_model(model, type = \"est\", show.values = TRUE, show.p = TRUE,\n                   title = \"Coefficient Plot for Mixed-Effects Logistic Regression\")\n\n\n\n\n\n\n\n\nThe coefficient plot presents the odds ratios (ORs) from a mixed-effects logistic regression model assessing the effect of time, treatment (terbinafine), and their interaction on a binary outcome. The odds ratio for time is 0.67 (95% CI excludes 1, p &lt; 0.001), indicating a significant decrease in the odds of the outcome over time. The odds ratio for treatment (terbinafine) is 0.74, with a wide confidence interval crossing 1, suggesting no statistically significant effect of treatment alone. The interaction between time and treatment (OR = 0.87, p &lt; 0.05) implies that the effect of time on the outcome differs significantly depending on the treatment, with the decrease in odds over time being slightly attenuated in the terbinafine group.\n\n# Generate effects for the interaction term\neff &lt;- allEffects(model)\nplot(eff, main = \"Effects Plot for Mixed-Effects Logistic Regression\")\n\n\n\n\n\n\n\n\nThe effects plot depicts the predicted probabilities of the binary outcome over time for two treatment groups (itraconazole and terbinafine), derived from the mixed-effects logistic regression model. For both treatments, the probability of the outcome decreases over time, as indicated by the downward slope of the lines. However, the rate of decrease appears slightly less pronounced for the terbinafine group compared to itraconazole, consistent with the significant time × treatment interaction observed in the coefficient plot. The shaded regions represent 95% confidence intervals, highlighting the model’s uncertainty, particularly at later time points where data sparsity is evident in the rug plot of observations along the x-axis.\nSimilar is the interpretation for the following diagram as well.\n\n# Get predicted probabilities\npred &lt;- ggpredict(model, terms = c(\"time [all]\", \"treatment\"))\n\n# Plot the interaction effects\nggplot(pred, aes(x = x, y = predicted, color = group)) +\n  geom_line(size = 1.2) +\n  geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = group), alpha = 0.2) +\n  labs(title = \"Predicted Probabilities by Time and Treatment\",\n       x = \"Time\",\n       y = \"Predicted Probability\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\n\n\nf) Fixed Effects Comparison from Different packages\n\nmodels_list &lt;- list(\n  glm_model = glm_model,\n  glmmPQL_model = glmmPQL_model,\n  glmer_model = glmer_model,\n  glmer_quad_model_10 = glmer_quad_model_10,\n  glmer_quad_model_20 = glmer_quad_model_20,\n  brms_model = model_brms\n)\n\n# Extract and arrange fixed effect coefficients for comparison\nfixed_effects_comparison &lt;- purrr::map_dfr(models_list, ~tidy(., effects = \"fixed\", conf.int=TRUE), .id = \"model\") |&gt;\n  dplyr::arrange(term)\n\n# View the comparison\nhead(fixed_effects_comparison)\n\n# A tibble: 6 × 11\n  model    term  estimate std.error statistic  p.value conf.low conf.high effect\n  &lt;chr&gt;    &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt; &lt;chr&gt; \n1 glm_mod… (Int…   -0.557     0.109     -5.11  3.25e-7   -0.772    -0.344 &lt;NA&gt;  \n2 glmmPQL… (Int…   -0.743     0.247     -3.01  2.62e-3   -1.23     -0.260 fixed \n3 glmer_m… (Int…   -2.51      0.764     -3.29  1.02e-3   -4.01     -1.01  fixed \n4 glmer_q… (Int…   -1.64      0.449     -3.65  2.60e-4   -2.52     -0.760 fixed \n5 glmer_q… (Int…   -1.62      0.433     -3.73  1.88e-4   -2.47     -0.769 fixed \n6 brms_mo… (Int…   -1.60      0.421     NA    NA         -2.48     -0.806 fixed \n# ℹ 2 more variables: df &lt;dbl&gt;, component &lt;chr&gt;\n\n\n\n# Plot fixed effects using ggplot2\nggplot(fixed_effects_comparison, aes(x = estimate, y = model, color = model)) +\n  geom_point() +\n  geom_errorbarh(aes(xmin = estimate - std.error, xmax = estimate + std.error), height = 0.2) +\n  facet_wrap(~term, scales = \"free\") +\n  labs(title = \"Coefficient Plot of Fixed Effects\",\n       x = \"Estimate\",\n       y = \"Model\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe fixed-effect estimates across the six modeling approaches—glm, glmmPQL, glmer, glmer_quad_10, glmer_quad_20, and brms—show varying degrees of agreement. For the intercept, the estimates range from -0.56 (glm_model) to -2.51 (glmer_model), indicating differences in how each approach estimates baseline probabilities. The brms and glmer_quad models yield estimates closer to each other (-1.59 to -1.64), while glm and glmmPQL models differ slightly or moderately from these. For the effect of time, most models produce very similar estimates around -0.39, except for glm_model, which shows a lower magnitude of -0.17, suggesting a methodological distinction. The interaction term time:treatmentterbinafine is consistent across the mixed-effects and Bayesian models, with estimates clustering around -0.137, while the glm model produces a smaller effect (-0.067). For the treatment-only effect, variability is more pronounced, with estimates ranging from near-zero (glm_model) to -0.30 (glmer_model), though this term appears to lack statistical significance across models. Overall, the estimates for time and its interaction are very similar across models, while the intercept and treatment-only effects show more variation.\n\ncredible_intervals &lt;- posterior_interval(model_brms, prob = 0.95)  \n# View the intervals\nhead(credible_intervals,4)\n\n                                  2.5%      97.5%\nb_Intercept                 -2.4826372 -0.8060465\nb_time                      -0.4859797 -0.3095742\nb_treatmentterbinafine      -1.2783963  0.9874379\nb_time:treatmentterbinafine -0.2722888 -0.0088164\n\n# prior_summary(model_brms)\n\nIn this analysis, a Bayesian logistic regression model was fitted using the brms package to examine the effects of time, treatment with terbinafine, and their interaction on a binary outcome. Credible intervals (95%) for the fixed effects were derived using posterior samples. The intercept had a credible interval of [-2.51, -0.81], while the effect of time showed a credible interval of [-0.48, -0.31]. The treatment effect of terbinafine had a wider credible interval of [-1.28, 0.98], suggesting greater uncertainty around its estimate. Notably, the interaction term between time and terbinafine treatment had a credible interval of [-0.28, -0.005], indicating a likely small but significant interaction effect. Default priors were utilized for fixed effects, which were flat (uninformative) priors, allowing the posterior distributions to be driven predominantly by the observed data. For random effects (e.g., varying intercepts by patient ID), weakly informative Student’s t-distribution priors were employed with three degrees of freedom, a mean of 0, and a scale parameter of 2.5, ensuring stability in estimating group-level variance while avoiding overly restrictive assumptions. These results highlight both the effectiveness of Bayesian modeling in quantifying uncertainty and the importance of considering prior choices in model interpretation."
  },
  {
    "objectID": "Project_4.html#simulation-study",
    "href": "Project_4.html#simulation-study",
    "title": "Project 4",
    "section": "3. Simulation Study",
    "text": "3. Simulation Study\n\nsimfun &lt;- function(beta, theta, n_t, n_id) {\n  # Create the dataset structure\n  data &lt;- expand.grid(\n    id = factor(seq_len(n_id)),      # n_id levels for the grouping variable\n    time = seq_len(n_t) - 1         # Integer time variable from 0 to n_t - 1\n  )\n  \n  # Randomly assign individuals to two treatment groups\n  data$ttt &lt;- factor(sample(c(\"A\", \"B\"), n_id, replace = TRUE))[as.numeric(data$id)]\n  \n  # Define the model formula\n  formula &lt;- ~ 1 + ttt * time + (1 | id)\n  \n  # Specify the parameters\n  params &lt;- list(\n    beta = beta,                   # Fixed-effect parameters\n    theta = theta                  # Random-effect parameters (on log scale)\n  )\n  \n  # Simulate response data using glmmTMB::simulate_new\n  sim_data &lt;- simulate_new(\n    object = formula,\n    newdata = data,\n    family = binomial(link = \"logit\"),         # Bernoulli response\n    newparams = params\n  )\n  \n  # Add the simulated response to the dataset\n  data$response &lt;- sim_data[[1]]\n  \n  return(data)\n}\n\n\nfitfun &lt;- function(data, nAGQ) {\n  # Fit the model based on the value of nAGQ\n  if (nAGQ == -2) {\n    # GLM (pooled model)\n    model &lt;- glm(response ~ 1 + ttt * time, data = data, family = binomial(link = \"logit\"))\n    result &lt;- broom.mixed::tidy(model, effects = \"fixed\", conf.int = TRUE)\n    } else if (nAGQ == -1) {\n    model &lt;- MASS::glmmPQL(response ~ 1 + ttt * time,\n                     random = ~ 1 | id,\n                     family = binomial(link = \"logit\"),\n                     data = data,\n                     verbose = FALSE)\n    result &lt;- broom.mixed::tidy(model, effects = \"fixed\", conf.int = TRUE)\n  } else if (nAGQ &gt;= 1) {\n    model &lt;- glmer(response ~ 1 + ttt * time + (1 | id), data = data, family = binomial(link = \"logit\"), nAGQ = nAGQ)\n    result &lt;- broom.mixed::tidy(model, effects = \"fixed\", conf.int = TRUE)\n    } else {\n      stop(\"Invalid value of nAGQ. Use -2, -1, or an integer &gt;= 1.\")\n      }\n    \n    results &lt;- result[, c(\"term\", \"estimate\", \"conf.low\", \"conf.high\")]\n    return(results)\n}\n\n\n# Function that fun sim_n number of simulations\nrun_sim &lt;- function(sim_n, nAGQ, beta, theta, n_t, n_id){\n  output &lt;- replicate(sim_n, fitfun(simfun(beta = beta, theta = theta, n_t = n_t, n_id = n_id), nAGQ = nAGQ), simplify = FALSE)\n  return(output)\n}\n\n# Intergrate the data into a data frame\nsum.data &lt;- function(data){\n  result_df &lt;- do.call(rbind, lapply(data, function(sim) {\n  data.frame(\n    intercept = sim$estimate[sim$term == \"(Intercept)\"],\n    conf.low.intercept = sim$conf.low[sim$term == \"(Intercept)\"],\n    conf.high.intercept = sim$conf.high[sim$term == \"(Intercept)\"],\n    tttB = sim$estimate[sim$term == \"tttB\"],\n    conf.low.tttB = sim$conf.low[sim$term == \"tttB\"],\n    conf.high.tttB = sim$conf.high[sim$term == \"tttB\"],\n    time = sim$estimate[sim$term == \"time\"],\n    conf.low.time = sim$conf.low[sim$term == \"time\"],\n    conf.high.time = sim$conf.high[sim$term == \"time\"],\n    interaction = sim$estimate[sim$term == \"tttB:time\"],\n    conf.low.interaction = sim$conf.low[sim$term == \"tttB:time\"],\n    conf.high.interaction = sim$conf.high[sim$term == \"tttB:time\"]\n  )}))\n  return(result_df)\n}\n\nmetrics_b2 &lt;- function(true_values, data) {\n  # Create an empty list to store results for each beta\n  results &lt;- list()\n  \n  # For b_2\n  bias &lt;- mean(data[,4]) - true_values[2]\n  var &lt;- var(data[,4])\n  scaled_rmse &lt;- sqrt(mean((data[,4] / true_values[2] - 1)^2))\n  coverage &lt;- mean(true_values[2] &gt;= data[,5] & true_values[2] &lt;= data[,6])\n  \n  # Store the results in the list\n  results$bias &lt;- bias\n  results$variance &lt;- var\n  results$scaled_rmse &lt;- scaled_rmse\n  results$coverage &lt;- coverage\n  \n  # Convert the results list to a data frame\n  return(as.data.frame(results))\n}\n\nmetrics_b4 &lt;- function(true_values, data) {\n  # Create an empty list to store results for each beta\n  results &lt;- list()\n  \n  # For b_4\n  bias &lt;- mean(data[,10]) - true_values[4]\n  var &lt;- var(data[,10])\n  scaled_rmse &lt;- sqrt(mean((data[,10] / true_values[4] - 1)^2))\n  coverage &lt;- mean(true_values[4] &gt;= data[,11] & true_values[4] &lt;= data[,12])\n  \n  # Store the results in the list\n  results$bias &lt;- bias\n  results$variance &lt;- var\n  results$scaled_rmse &lt;- scaled_rmse\n  results$coverage &lt;- coverage\n  \n  # Convert the results list to a data frame\n  return(as.data.frame(results))\n}\n\n\n## options(timeout = 600)\n## Simulation Using \nset.seed(123)\nbeta &lt;- c(-0.6, 0, -0.2, -0.05)\ntheta &lt;- log(0.2)\nn_id &lt;- 300\nn_sim &lt;- 100\n\n\n##############  100 Simulations for n_t = 5  ######################################\nn_t &lt;- 5\n# Initialize empty lists to store the metrics for b4\nb2_metrics &lt;- list()\n\n# Simulations for nAGQ = -2 (glm model)\nnAGQ &lt;- -2\nsim_output &lt;- run_sim(n_sim, nAGQ, beta, theta, n_t, n_id)\noutput_glm_5 &lt;- sum.data(sim_output)\n\n\n# Simulations for nAGQ = -1 (PQL model)\nnAGQ &lt;- -1\nsim_output &lt;- run_sim(n_sim, nAGQ, beta, theta, n_t, n_id)\noutput_PQL_5 &lt;- sum.data(sim_output)\n\n\n# Simulations for nAGQ = 1 (Laplace model)\nnAGQ &lt;- 1\nsim_output &lt;- run_sim(n_sim, nAGQ, beta, theta, n_t, n_id)\noutput_LAPLACE_5 &lt;- sum.data(sim_output)\n\n\n# Simulations for nAGQ = 5 (AGHQ model)\nnAGQ &lt;- 5\nsim_output &lt;- run_sim(n_sim, nAGQ, beta, theta, n_t, n_id)\noutput_AGHQ_5 &lt;- sum.data(sim_output)\n\n\n##############  100 Simulations for n_t = 5 for b2  ###############################\n\n# Initialize empty lists to store the metrics for b2\nb2_metrics &lt;- list()\n\n# Simulations for nAGQ = -2 (glm model)\nb2_metrics_glm &lt;- metrics_b2(beta, output_glm_5)\n# Store the results for glm model\nb2_metrics$glm &lt;- b2_metrics_glm\n\n# Simulations for nAGQ = -1 (PQL model)\nb2_metrics_PQL &lt;- metrics_b2(beta, output_PQL_5)\n# Store the results for PQL model\nb2_metrics$PQL &lt;- b2_metrics_PQL\n\n# Simulations for nAGQ = 1 (Laplace model)\nb2_metrics_LAPLACE &lt;- metrics_b2(beta, output_LAPLACE_5)\n# Store the results for Laplace model\nb2_metrics$Laplace &lt;- b2_metrics_LAPLACE\n\n# Simulations for nAGQ = 5 (AGHQ model)\nb2_metrics_AGHQ &lt;- metrics_b2(beta, output_AGHQ_5)\n# Store the results for AGHQ model\nb2_metrics$AGHQ &lt;- b2_metrics_AGHQ\n\n# Convert the lists of metrics to data frames\nb2_metrics_df &lt;- do.call(rbind, b2_metrics)\n\n# Optionally, name the rows for easy reference\nrownames(b2_metrics_df) &lt;- c(\"glm\", \"PQL\", \"Laplace\", \"AGHQ\")\n\n# Transpose the data frame to switch rows and columns\nb2_metrics_df_transposed &lt;- t(b2_metrics_df)\n\n# Return the transposed data frame\nb2_metrics_df_transposed\n\n                    glm         PQL       Laplace       AGHQ\nbias        -0.04129691 -0.01875058 -0.0002026514 0.01287910\nvariance     0.03784005  0.03739414  0.0392600328 0.03737139\nscaled_rmse         Inf         Inf           Inf        Inf\ncoverage     0.95000000  0.94000000  0.9500000000 0.95000000\n\n\n\nmethods &lt;- c(\"glm\", \"PQL\", \"Laplace\", \"AGHQ\")\nmetrics &lt;- data.frame(\n  method = rep(methods, times = 3),\n  bias = b2_metrics_df_transposed[1, ],   # assuming these rows are correct\n  variance = b2_metrics_df_transposed[2, ],\n  coverage = b2_metrics_df_transposed[4, ],\n  row.names = NULL  # Ensure no row names are carried over\n)\n\n\n# Pivot the data longer for ggplot\nmetrics_long &lt;- metrics %&gt;%\n  pivot_longer(cols = c(bias, variance, coverage), names_to = \"metric\", values_to = \"value\")\n\n# Plotting\nggplot(metrics_long, aes(x = method, y = value, fill = metric)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", width = 0.7) +\n  facet_wrap(~metric, scales = \"free_y\", nrow = 1) +\n  scale_fill_brewer(palette = \"Set3\") +  # Set a nice color palette\n  labs(\n    title = \"Comparison for b2 of Metrics Across Methods (n_t = 5)\",\n    x = \"Method\",\n    y = \"Value\",\n    fill = \"Metric\"\n  ) +\n  theme_minimal(base_size = 14) +  # Increase base size for better readability\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis text for clarity\n    strip.text = element_text(size = 12),  # Adjust facet labels\n    legend.position = \"top\",  # Place legend at the top\n    legend.title = element_blank()  # Remove legend title\n  )\n\n\n\n\n\n\n\n\nThis plot compares the performance of four methods (AGHQ, glm, Laplace, PQL) for parameter b2 across three metrics: bias, coverage, and variance, with n_t = 5. The bias plot indicates that the glm method exhibits the largest negative bias, while AGHQ and PQL show minor positive bias. Coverage rates are consistently high across all methods, hovering near 1.0, demonstrating reliable interval performance. In terms of variance, all methods have comparable values, with AGHQ showing slightly higher variance compared to the others. These findings suggest that AGHQ and PQL provide relatively unbiased estimates while maintaining acceptable coverage and variance levels.\n\n\n##############  100 Simulations for n_t = 5 for b4  ###############################\n# Initialize empty lists to store the metrics for b4\nb4_metrics &lt;- list()\n\n# Simulations for nAGQ = -2 (glm model)\nb4_metrics_glm &lt;- metrics_b4(beta, output_glm_5)\n# Store the results for glm model\nb4_metrics$glm &lt;- b4_metrics_glm\n\n\n# Simulations for nAGQ = -1 (PQL model)\nb4_metrics_PQL &lt;- metrics_b4(beta, output_PQL_5)\n# Store the results for PQL model\nb4_metrics$PQL &lt;- b4_metrics_PQL\n\n\n# Simulations for nAGQ = 1 (Laplace model)\nb4_metrics_LAPLACE &lt;- metrics_b4(beta, output_LAPLACE_5)\n# Store the results for Laplace model\nb4_metrics$Laplace &lt;- b4_metrics_LAPLACE\n\n\n# Simulations for nAGQ = 5 (AGHQ model)\nb4_metrics_AGHQ &lt;- metrics_b4(beta, output_AGHQ_5)\n# Store the results for AGHQ model\nb4_metrics$AGHQ &lt;- b4_metrics_AGHQ\n\n# Convert the lists of metrics to data frames\nb4_metrics_df &lt;- do.call(rbind, b4_metrics)\n\n# Optionally, name the rows for easy reference\nrownames(b4_metrics_df) &lt;- c(\"glm\", \"PQL\", \"Laplace\", \"AGHQ\")\n\n# Transpose the data frame to switch rows and columns\nb4_metrics_df_transposed &lt;- t(b4_metrics_df)\n\n# Return the transposed data frame\nb4_metrics_df_transposed\n\n                    glm         PQL      Laplace         AGHQ\nbias        0.018385112 0.006606813 0.0007789964 0.0004380779\nvariance    0.008408592 0.008513147 0.0079322476 0.0064752050\nscaled_rmse 1.861453077 1.840833064 1.7724031072 1.6013300489\ncoverage    0.900000000 0.930000000 0.9700000000 0.9700000000\n\n\n\n# Define methods\nmethods &lt;- c(\"glm\", \"PQL\", \"Laplace\", \"AGHQ\")\n\n# Create the metrics data frame\nmetrics &lt;- data.frame(\n  metric = rep(c(\"bias\", \"variance\", \"scaled_rmse\", \"coverage\"), each = 4),\n  method = rep(methods, times = 4),\n  value = c(b4_metrics_df_transposed[1,], \n            b4_metrics_df_transposed[2,],\n            b4_metrics_df_transposed[3,],\n            b4_metrics_df_transposed[4,])\n)\n\n# Plotting\nggplot(metrics, aes(x = method, y = value, fill = metric)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", width = 0.7) +  # Adjust bar width for better spacing\n  facet_wrap(~metric, scales = \"free_y\", nrow = 1) +  # Arrange metrics in a single row\n  scale_fill_brewer(palette = \"Set3\") +  # Apply a custom color palette\n  labs(\n    title = \"Comparison for b4 of Metrics Across Methods (n_t = 5)\",  # Main plot title\n    x = \"Method\",  # X-axis label\n    y = \"Metric Value\",  # Y-axis label\n    fill = \"Metric\"  # Legend label for fill\n  ) +\n  theme_minimal(base_size = 14) +  # Use a clean theme and set base font size\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels for readability\n    strip.text = element_text(size = 12),  # Increase size of facet labels\n    legend.position = \"top\",  # Move the legend to the top\n    legend.title = element_blank(),  # Remove legend title for simplicity\n    panel.spacing = unit(1, \"lines\")  # Increase space between facets\n  )\n\n\n\n\n\n\n\n\nThis plot illustrates the metrics bias, coverage, scaled RMSE, and variance for parameter b4 across four methods (AGHQ, glm, Laplace, PQL) with n_t = 5. Bias results indicate AGHQ is nearly unbiased, while PQL has a notable positive bias. Coverage is consistently high across all methods, remaining close to 1.0. Scaled RMSE values are slightly higher for Laplace and PQL compared to AGHQ and glm, reflecting differences in accuracy. Variance is lowest for AGHQ and highest for PQL, highlighting AGHQ’s balance between precision and accuracy. Overall, AGHQ demonstrates the most favorable performance with low bias, high coverage, and moderate variance.\n\n## options(timeout = 600)\n## Simulation Using \nset.seed(123)\nbeta &lt;- c(-0.6, 0, -0.2, -0.05)\ntheta &lt;- log(0.2)\nn_id &lt;- 300\nn_sim &lt;- 100\n\n\n##############  100 Simulations for n_t = 10  #####################################\nn_t &lt;- 10\n# Initialize empty lists to store the metrics for b4\nb2_metrics &lt;- list()\n\n# Simulations for nAGQ = -2 (glm model)\nnAGQ &lt;- -2\nsim_output &lt;- run_sim(n_sim, nAGQ, beta, theta, n_t, n_id)\noutput_glm_10 &lt;- sum.data(sim_output)\n\n\n# Simulations for nAGQ = -1 (PQL model)\nnAGQ &lt;- -1\nsim_output &lt;- run_sim(n_sim, nAGQ, beta, theta, n_t, n_id)\noutput_PQL_10 &lt;- sum.data(sim_output)\n\n\n# Simulations for nAGQ = 1 (Laplace model)\nnAGQ &lt;- 1\nsim_output &lt;- run_sim(n_sim, nAGQ, beta, theta, n_t, n_id)\noutput_LAPLACE_10 &lt;- sum.data(sim_output)\n\n\n# Simulations for nAGQ = 5 (AGHQ model)\nnAGQ &lt;- 5\nsim_output &lt;- run_sim(n_sim, nAGQ, beta, theta, n_t, n_id)\noutput_AGHQ_10 &lt;- sum.data(sim_output)\n\n\n##############  100 Simulations for n_t = 10 for b2  ##############################\n\n# Initialize empty lists to store the metrics for b2\nb2_metrics &lt;- list()\n\n# Simulations for nAGQ = -2 (glm model)\nb2_metrics_glm &lt;- metrics_b2(beta, output_glm_10)\n# Store the results for glm model\nb2_metrics$glm &lt;- b2_metrics_glm\n\n\n# Simulations for nAGQ = -1 (PQL model)\nb2_metrics_PQL &lt;- metrics_b2(beta, output_PQL_10)\n# Store the results for PQL model\nb2_metrics$PQL &lt;- b2_metrics_PQL\n\n\n# Simulations for nAGQ = 1 (Laplace model)\nb2_metrics_LAPLACE &lt;- metrics_b2(beta, output_LAPLACE_10)\n# Store the results for Laplace model\nb2_metrics$Laplace &lt;- b2_metrics_LAPLACE\n\n\n# Simulations for nAGQ = 5 (AGHQ model)\nb2_metrics_AGHQ &lt;- metrics_b2(beta, output_AGHQ_10)\n# Store the results for AGHQ model\nb2_metrics$AGHQ &lt;- b2_metrics_AGHQ\n\n\n# Convert the lists of metrics to data frames\nb2_metrics_df &lt;- do.call(rbind, b2_metrics)\n\n# Optionally, name the rows for easy reference\nrownames(b2_metrics_df) &lt;- c(\"glm\", \"PQL\", \"Laplace\", \"AGHQ\")\n\n# Transpose the data frame to switch rows and columns\nb2_metrics_df_transposed &lt;- t(b2_metrics_df)\n\n# Return the transposed data frame\nb2_metrics_df_transposed\n\n                    glm          PQL     Laplace       AGHQ\nbias        0.006258034 -0.006838937 -0.02297344 0.02445127\nvariance    0.022098072  0.023205626  0.02426724 0.02782000\nscaled_rmse         Inf          Inf         Inf        Inf\ncoverage    0.960000000  0.940000000  0.96000000 0.95000000\n\n\n\nmethods &lt;- c(\"glm\", \"PQL\", \"Laplace\", \"AGHQ\")\nmetrics &lt;- data.frame(\n  method = rep(methods, times = 3),\n  bias = b2_metrics_df_transposed[1, ],   # assuming these rows are correct\n  variance = b2_metrics_df_transposed[2, ],\n  coverage = b2_metrics_df_transposed[4, ],\n  row.names = NULL  # Ensure no row names are carried over\n)\n\n\n# Pivot the data longer for ggplot\nmetrics_long &lt;- metrics %&gt;%\n  pivot_longer(cols = c(bias, variance, coverage), names_to = \"metric\", values_to = \"value\")\n\n# Plotting\nggplot(metrics_long, aes(x = method, y = value, fill = metric)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", width = 0.7) +\n  facet_wrap(~metric, scales = \"free_y\", nrow = 1) +\n  scale_fill_brewer(palette = \"Set3\") +  # Set a nice color palette\n  labs(\n    title = \"Comparison for b2 of Metrics Across Methods (n_t = 10)\",\n    x = \"Method\",\n    y = \"Value\",\n    fill = \"Metric\"\n  ) +\n  theme_minimal(base_size = 14) +  # Increase base size for better readability\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis text for clarity\n    strip.text = element_text(size = 12),  # Adjust facet labels\n    legend.position = \"top\",  # Place legend at the top\n    legend.title = element_blank()  # Remove legend title\n  )\n\n\n\n\n\n\n\n\nThis plot evaluates the performance of four methods (AGHQ, glm, Laplace, PQL) for parameter b2 across bias, coverage, and variance metrics, with n_t = 10. AGHQ shows a slight positive bias, while glm exhibits minimal bias, and Laplace has a small negative bias. Coverage rates remain consistently high across all methods, indicating robust interval estimation. Variance is highest for AGHQ and lowest for PQL, with glm and Laplace falling in between. These results suggest that glm offers a favorable trade-off between low bias and moderate variance while maintaining excellent coverage.\n\n##############  100 Simulations for n_t = 5 for b4  ###############################\n# Initialize empty lists to store the metrics for b4\nb4_metrics &lt;- list()\n\n# Simulations for nAGQ = -2 (glm model)\nb4_metrics_glm &lt;- metrics_b4(beta, output_glm_10)\n# Store the results for glm model\nb4_metrics$glm &lt;- b4_metrics_glm\n\n\n# Simulations for nAGQ = -1 (PQL model)\nb4_metrics_PQL &lt;- metrics_b4(beta, output_PQL_10)\n# Store the results for PQL model\nb4_metrics$PQL &lt;- b4_metrics_PQL\n\n\n# Simulations for nAGQ = 1 (Laplace model)\nb4_metrics_LAPLACE &lt;- metrics_b4(beta, output_LAPLACE_10)\n# Store the results for Laplace model\nb4_metrics$Laplace &lt;- b4_metrics_LAPLACE\n\n\n# Simulations for nAGQ = 5 (AGHQ model)\nb4_metrics_AGHQ &lt;- metrics_b4(beta, output_AGHQ_10)\n# Store the results for AGHQ model\nb4_metrics$AGHQ &lt;- b4_metrics_AGHQ\n\n# Convert the lists of metrics to data frames\nb4_metrics_df &lt;- do.call(rbind, b4_metrics)\n\n# Optionally, name the rows for easy reference\nrownames(b4_metrics_df) &lt;- c(\"glm\", \"PQL\", \"Laplace\", \"AGHQ\")\n\n# Transpose the data frame to switch rows and columns\nb4_metrics_df_transposed &lt;- t(b4_metrics_df)\n\n# Return the transposed data frame\nb4_metrics_df_transposed\n\n                     glm          PQL     Laplace         AGHQ\nbias        -0.002159583 0.0006114208 0.007422869 -0.003354739\nvariance     0.001152805 0.0014086545 0.001306414  0.001328255\nscaled_rmse  0.677034799 0.7469783954 0.734424599  0.728347903\ncoverage     1.000000000 0.9400000000 0.950000000  0.930000000\n\n\n\n# Define methods\nmethods &lt;- c(\"glm\", \"PQL\", \"Laplace\", \"AGHQ\")\n\n# Create the metrics data frame\nmetrics &lt;- data.frame(\n  metric = rep(c(\"bias\", \"variance\", \"scaled_rmse\", \"coverage\"), each = 4),\n  method = rep(methods, times = 4),\n  value = c(b4_metrics_df_transposed[1,], \n            b4_metrics_df_transposed[2,],\n            b4_metrics_df_transposed[3,],\n            b4_metrics_df_transposed[4,])\n)\n\n# Plotting\nggplot(metrics, aes(x = method, y = value, fill = metric)) +\n  geom_bar(stat = \"identity\", position = \"dodge\", width = 0.7) +  # Adjust bar width for better spacing\n  facet_wrap(~metric, scales = \"free_y\", nrow = 1) +  # Arrange metrics in a single row\n  scale_fill_brewer(palette = \"Set3\") +  # Apply a custom color palette\n  labs(\n    title = \"Comparison for b4 of Metrics Across Methods (n_t = 10)\",  # Main plot title\n    x = \"Method\",  # X-axis label\n    y = \"Metric Value\",  # Y-axis label\n    fill = \"Metric\"  # Legend label for fill\n  ) +\n  theme_minimal(base_size = 14) +  # Use a clean theme and set base font size\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels for readability\n    strip.text = element_text(size = 12),  # Increase size of facet labels\n    legend.position = \"top\",  # Move the legend to the top\n    legend.title = element_blank(),  # Remove legend title for simplicity\n    panel.spacing = unit(1, \"lines\")  # Increase space between facets\n  )\n\n\n\n\n\n\n\n\nThe graph displays a comprehensive comparison of four different statistical metrics (bias, coverage, scaled_rmse, and variance) across four methods (AGHQ, glm, Laplace, and PQL) for a parameter b4 with n_t = 10. Notably, the Laplace method shows the highest positive bias around 0.006, while AGHQ and glm demonstrate slight negative bias. Coverage rates are consistently high across all methods, maintaining values above 0.75. The scaled root mean square error (scaled_rmse) exhibits similar values across methods, ranging approximately between 0.4 and 0.7. Variance measurements are relatively small across all methods, with values falling in the range of 0.0005 to 0.0015, though PQL shows marginally higher variance compared to the other methods. This visualization effectively illustrates the relative performance and trade-offs between these different statistical approaches."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Advanced Linear Models",
    "section": "",
    "text": "This site contains interactive versions of the projects.\n\nProject 1\nProject 2\nProject 3\nProject 4\nProject 5"
  },
  {
    "objectID": "Project_1.html",
    "href": "Project_1.html",
    "title": "Project 1",
    "section": "",
    "text": "# load libraries\nlibrary(tidyverse)\nlibrary(dotwhisker)\nlibrary(effects)\nlibrary(lemon)\nlibrary(MASS)\nlibrary(dplyr)\nlibrary(glmmTMB)\nlibrary(ggplot2)\nlibrary(performance)\nlibrary(AER)\nlibrary(caret)\nlibrary(see)\nlibrary(DHARMa)\nlibrary(patchwork)\nlibrary(mlmRev)\nlibrary(coefplot)"
  },
  {
    "objectID": "Project_1.html#a.-model-complexity-and-predictor-selection",
    "href": "Project_1.html#a.-model-complexity-and-predictor-selection",
    "title": "Project 1",
    "section": "a. Model Complexity and Predictor Selection",
    "text": "a. Model Complexity and Predictor Selection\nIn accordance with Harrell’s guidelines [@harrell], it is recommended that the optimal number of predictor variables in a regression model should be less than \\(\\frac{m}{15}\\) (depends on the skewness of the distribution etc.), where m is the limiting sample size, defined as nrow(mydata). Given that there are no strict limitations on the number of predictors in this analysis due to the sufficiently large sample size, I have opted to maintain a relatively simple and interpretable linear model.\nFor this analysis, I have selected two predictor variables (they are less correlated):\n\nThe natural logarithm of Gross Domestic Product (log_gdp).\nThe natural logarithm of the Population (log_pop).\n\nThe response variable of interest is the natural logarithm of gold medals (\\(\\log_n\\)), which will be estimated in this model (it was necessary to do a transformation such that: \\(\\log_n = \\log(n+1)\\), due to zeros in the dataset). This approach aims to facilitate interpretation while ensuring the model remains robust."
  },
  {
    "objectID": "Project_1.html#b.-variable-scaling-transformations-and-interpretation-thresholds",
    "href": "Project_1.html#b.-variable-scaling-transformations-and-interpretation-thresholds",
    "title": "Project 1",
    "section": "b. Variable Scaling, Transformations, and Interpretation Thresholds",
    "text": "b. Variable Scaling, Transformations, and Interpretation Thresholds\nThe response variable in this analysis is the natural logarithm of the number of gold medals won by each country in a given year, denoted as log_n, where n represents the count of gold medals. This transformation is unitless, though it represents a logarithmic transformation of a count variable.\nThe two predictor variables used in the model are:\n\nThe natural logarithm of Gross Domestic Product (GDP), denoted as log_gdp, where GDP is typically expressed in dollars.\nThe natural logarithm of population, denoted as log_pop, with the original variable representing the count of people.\n\nBoth of the are basically unitless.\nGiven the nature of the problem and the logarithmic transformations applied to both the response and predictor variables, defining thresholds in terms of absolute units becomes challenging. For example, determining what constitutes a “small” change in GDP is difficult due to the variation in economic significance across countries.\nAs a result, I have adopted a threshold of 1% on each variable in the log scale. This approach provides a consistent way to interpret changes in the predictor variables and helps to identify significant relationships while managing noise in the model. Specifically, a 1% change in the log scale reflects the relative change in the original variable, offering a practical and scalable criterion for evaluating small changes in each predictor variable."
  },
  {
    "objectID": "Project_1.html#c.-model-specification",
    "href": "Project_1.html#c.-model-specification",
    "title": "Project 1",
    "section": "c. Model Specification",
    "text": "c. Model Specification\nWe applied the following model\n\n# original model\nmodel &lt;- lm(log_n ~ log_gdp+log_pop, data = mydata)\n\n# View summary of the model\nsummary(model)\n\n\nCall:\nlm(formula = log_n ~ log_gdp + log_pop, data = mydata)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.08919 -0.65611 -0.07442  0.54266  2.82003 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.77938    0.10621  -7.338 8.03e-13 ***\nlog_gdp      0.38106    0.03119  12.216  &lt; 2e-16 ***\nlog_pop     -0.01074    0.03575  -0.300    0.764    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9701 on 538 degrees of freedom\n  (94 observations deleted due to missingness)\nMultiple R-squared:  0.3604,    Adjusted R-squared:  0.358 \nF-statistic: 151.6 on 2 and 538 DF,  p-value: &lt; 2.2e-16\n\n\nThe model summary indicates that approximately 36% of the variability in the response variable is explained by the predictors included in the model. The natural logarithm of GDP (log_gdp) emerges as a highly significant predictor, with a strong association with the response variable. In contrast, the natural logarithm of Population (log_pop) appears to be statistically insignificant and may not contribute meaningfully to the model.\nHowever, before drawing definitive conclusions, it is essential to conduct diagnostic tests to evaluate the model’s reliability and ensure that key assumptions, such as residual normality, homoscedasticity, and independence, are met. These diagnostics will provide a more comprehensive understanding of the model’s validity and its potential limitations."
  },
  {
    "objectID": "Project_1.html#d.-model-diagnostics-and-assessment-of-assumptions",
    "href": "Project_1.html#d.-model-diagnostics-and-assessment-of-assumptions",
    "title": "Project 1",
    "section": "d. Model Diagnostics and Assessment of Assumptions",
    "text": "d. Model Diagnostics and Assessment of Assumptions\nTo assess the assumptions of our linear regression model, we examined several diagnostic plots.\n\nResiduals vs. Fitted: The plot reveals a moderate V-shaped pattern, indicating a potential non-linear relationship between the predictors and the response variable. This suggests that the linear model may not adequately capture the underlying relationship.\nQ-Q Plot: The Q-Q plot demonstrates deviations in the tails from the theoretical quantiles of the Normal distribution. While this suggests violations of the normality assumption, it is important to note that Q-Q plots are not always the most reliable method for assessing normality.\nScale-Location Plot: This plot indicates a clear upward trend, suggesting that the assumption of homoscedasticity (constant variance of the residuals) is violated. The presence of heteroscedasticity could impact the validity of the regression results.\nPosterior Predictive Plot: The model’s ability to simulate the distribution of the observed data is insufficient, as indicated by the discrepancies in the posterior predictive plot. This further underscores the limitations of the current model.\nCollinearity Assessment: In contrast, the collinearity diagnostics suggest that there is no significant collinearity among the predictor variables. While collinearity is generally not a major concern for linear models, it is still a positive finding.\n\n\n# plot model evaluation graphs\nperformance::check_model(model)\n\n\n\n\n\n\n\n\nIn summary, the diagnostic plots indicate several violations of model assumptions, particularly regarding linearity, normality, and homoscedasticity, which may necessitate model reassessment or alternative modeling approaches."
  },
  {
    "objectID": "Project_1.html#e.-model-revision-and-selection-of-an-appropriate-count-regression",
    "href": "Project_1.html#e.-model-revision-and-selection-of-an-appropriate-count-regression",
    "title": "Project 1",
    "section": "e. Model Revision and Selection of an Appropriate Count Regression",
    "text": "e. Model Revision and Selection of an Appropriate Count Regression\nThe initial linear regression model was found to be inappropriate for the data at hand. The response variable, the number of medals (n), is a count variable, and using a linear model to predict count data can lead to biased estimates and violations of key assumptions, as evidenced by the diagnostic plots.\nGiven the nature of the response variable, I have opted for a Negative Binomial (NB) regression model. The Negative Binomial model is particularly well-suited for count data and is commonly used when the data exhibits over-dispersion—a scenario where the variance exceeds the mean. Over-dispersion appears to be a significant issue in this case, making the NB regression an appropriate choice.\nIn the NB regression model, I will use the original response variable (n) rather than its logarithmic transformation. The predictors will be the natural logarithm of GDP per capita (log_gdp_perC) and the natural logarithm of population (log_pop). This approach allows for a better fit of the data and addresses the limitations observed in the initial linear model, particularly in handling the over-dispersion inherent in the data.\n\n## Test for Over-dispersion : dispersiontest(nb_model)\n\n# Fit Negative Binomial regression model\nnb_model &lt;- glm.nb(n ~ log_pop + log_gdp_perC, data = mydata)\n\n# View summary of the nb_model\nsummary(nb_model)\n\n\nCall:\nglm.nb(formula = n ~ log_pop + log_gdp_perC, data = mydata, init.theta = 0.3548300421, \n    link = log)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)  -1.90041    0.22471  -8.457   &lt;2e-16 ***\nlog_pop       0.61990    0.04987  12.431   &lt;2e-16 ***\nlog_gdp_perC  0.63563    0.06174  10.295   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for Negative Binomial(0.3548) family taken to be 1)\n\n    Null deviance: 795.35  on 540  degrees of freedom\nResidual deviance: 492.81  on 538  degrees of freedom\n  (94 observations deleted due to missingness)\nAIC: 2230.6\n\nNumber of Fisher Scoring iterations: 1\n\n              Theta:  0.3548 \n          Std. Err.:  0.0312 \n\n 2 x log-likelihood:  -2222.5810 \n\n# plot nb_model evaluation graphs\nperformance::check_model(nb_model)\n\n\n\n\n\n\n\n### check for collinearity\n### vif less than 3 indicate no significant\nvif(nb_model)\n\n     log_pop log_gdp_perC \n    1.062566     1.062566 \n\n## Pseudo R^2\nperformance::r2(nb_model)\n\n# R2 for Generalized Linear Regression\n  Nagelkerke's R2: 0.556\n\n## Predictive Performance (Cross-validation)\n## train_control &lt;- trainControl(method=\"cv\", number=10)\n## train(ln ~ log_gdp_perC + log_pop, data=mydata, method=\"glm.nb\", trControl=train_control)\n\nLooking at the summary results, the model reveals that both population size and GDP per capita are significant predictors of Olympic gold medal success. Specifically, a 1% increase in population is associated with approximately a 0.62% increase in the expected number of gold medals, while a 1% increase in GDP per capita corresponds to about a 0.64% increase in expected medals. These findings suggest that countries with larger populations and higher economic resources are more likely to perform well in the Olympics, underscoring the importance of demographic and economic factors in athletic achievement. Moreover, theta = 0.3548, which is something that creates evidence for the over-dispersion nature of data.\nThe diagnostic graphs provide valuable insights into the model’s performance. The Q-Q plot indicates a relatively strong fit, suggesting that the residuals conform closely to a normal distribution. One critical assumption of the model is the absence of influential observations, which is confirmed by the analysis of influential observations. While there are some minor discrepancies between the observed and predicted residual variances, the overall model fit remains satisfactory.\nFurthermore, the analysis shows no signs of collinearity among the predictor variables. The results of the posterior predictive checks are also favorable. However, the robustness of these findings may warrant further investigation, as the overall goodness of fit raises the possibility of potential overfitting or other specification issues that should be explored to ensure the reliability of the model."
  },
  {
    "objectID": "Project_1.html#f.-coefficient-plot",
    "href": "Project_1.html#f.-coefficient-plot",
    "title": "Project 1",
    "section": "f. Coefficient Plot",
    "text": "f. Coefficient Plot\nTo draw a coefficient plot:\n\n# model coefficient plot\ndwplot(x=nb_model)\n\n\n\n\n\n\n\n\nI have chosen not to scale and center the predictors because we have only two quantitative variables, which allows for straightforward interpretation of the coefficients."
  },
  {
    "objectID": "Project_1.html#g.-effect-plot",
    "href": "Project_1.html#g.-effect-plot",
    "title": "Project 1",
    "section": "g. Effect Plot",
    "text": "g. Effect Plot\nTo draw an effects plot, we have:\n\n# Plot an effect plot and Effects of Predictors on the Model\neffects::allEffects(nb_model)\n\n model: n ~ log_pop + log_gdp_perC\n\n log_pop effect\nlog_pop\n        -2        0.1          3          5          7 \n 0.1577998  0.5800481  3.5010293 12.0957119 41.7894949 \n\n log_gdp_perC effect\nlog_gdp_perC\n       -1       0.1         2         3         4 \n0.3645483 0.7335204 2.4542054 4.6340731 8.7501368 \n\nplot(allEffects(nb_model))\n\n\n\n\n\n\n\n\nAs the logarithm of population increases, the expected number of gold medals (n) increases significantly, demonstrating a strong positive relationship. Similarly, as the logarithm of GDP per capita increases, the expected number of gold medals also increases, indicating that higher economic resources are associated with better Olympic performance. These effects illustrate the influence of population size and economic capacity on the success of countries in the Olympic Games."
  },
  {
    "objectID": "Project_5.html",
    "href": "Project_5.html",
    "title": "STATS 720 Project",
    "section": "",
    "text": "# Load data\ndata(\"Contraception\", package = \"mlmRev\")\n\n# Creation of a new column called \"u\"\nContraception &lt;- transform(\n  Contraception,\n  use_num = as.numeric(use)-1,\n  urban = factor(Contraception$urban, levels = c(\"N\", \"Y\"))\n  )\nhead(Contraception)\n\n  woman district use livch      age urban use_num\n1     1        1   N    3+  18.4400     Y       0\n2     2        1   N     0  -5.5599     Y       0\n3     3        1   N     2   1.4400     Y       0\n4     4        1   N    3+   8.4400     Y       0\n5     5        1   N     0 -13.5590     Y       0\n6     6        1   N     0 -11.5600     Y       0\n\n\nThis study investigates the hierarchical effects and determinants of contraceptive use in urban and rural Bangladesh, leveraging data from the 1989 Bangladesh Fertility Survey (BFS). A total of 11,905 ever-married women of reproductive age (10–49 years) were surveyed across urban and rural settings. The primary objective was to explore the demographic, socio-economic, cultural, and decision-making factors influencing contraceptive use, while accounting for the nested structure of the data through multilevel logistic regression modeling. Women were grouped within census blocks, which were further nested within regions, enabling the study to examine both individual-level and contextual determinants.\nKey findings from the original study highlight significant insights into contraceptive use patterns. Factors positively associated with contraceptive use included higher parity, women’s education, female independence scores, and joint family planning decisions, underscoring the importance of education and autonomy in reproductive health choices. Conversely, child mortality exhibited a significant negative influence, as experiences of child loss deterred contraceptive adoption. Urban-rural differences revealed notable disparities: urban women reported higher education, independence, and contraceptive use, while rural women experienced higher child mortality and lower autonomy and educational attainment. Hierarchical variation at the block level emphasized localized disparities in access to family planning resources and socio-cultural influences, particularly in remote rural areas. Interestingly, while religion and women’s work experience were found to have limited influence overall, younger rural women showed a positive association between work status and contraceptive use.\nThe current dataset, while a subset of the original BFS data, offers an opportunity to revisit these questions and refine our understanding of contraceptive use dynamics in Bangladesh. By analyzing the data through a similar multilevel framework, we aim to replicate and extend the findings, examining whether the determinants and hierarchical variations observed in the original study persist. This analysis will help to validate previous conclusions and provide updated insights into the interplay of socio-economic, demographic, and cultural factors shaping contraceptive use across urban and rural settings (in a much shorter scale as we have much less data and variables).\n\n\nBefore specifying the modeling process, it is essential to visually explore the data to gain valuable insights into its structure, relationships, and patterns. Graphical representations allow for an intuitive understanding of the data’s key features, enabling informed decisions about the modeling strategy, potential transformations, and variable selection. This step provides a foundation for identifying trends, outliers, and potential interactions, which are crucial for constructing effective and interpretable models.\n\nggplot(Contraception, aes(x = age, y = use_num)) +\n  geom_jitter(\n    height = 0.05, width = 0, alpha = 0.4, size = 1.5, color = \"lightblue\"\n  ) + \n  geom_smooth(\n    method = \"loess\", color = \"steelblue\", se = TRUE, linewidth = 1.2, span = 0.8, formula = 'y~x'\n  ) +\n  scale_y_continuous(\n    breaks = c(0, 1),\n    labels = c(\"Not Using\", \"Using\")\n  ) +\n  labs(\n    title = \"Contraception Usage vs Age\",\n    subtitle = \"Smoothed trend with jittered raw data points\",\n    x = \"Age (in years)\", \n    y = \"Contraception Usage\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    plot.subtitle = element_text(hjust = 0.5),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\n\n\n\n\nThe relationship between age and contraception usage exhibits a clear non-linear trend, as shown in the graph. Contraception usage increases with age during younger adulthood, peaks at mid-range ages, and then declines in older age, forming a curved pattern. This suggests that individuals in middle age are more likely to use contraception compared to younger or older individuals. The jittered raw data points highlight the binary nature of the response (“Using” vs. “Not Using”), with more individuals in the “Not Using” category at both age extremes. The shaded confidence interval around the smoothed trend line reflects greater variability at the younger and older ends of the age spectrum, reinforcing the need for targeted analysis when considering age-related contraception usage trends.\n\nggplot(Contraception, aes(x = age, y = use_num, color = urban)) +\n  geom_jitter(alpha = 0.4, width = 0.3, height = 0.05, size = 1.5) +\n  geom_smooth(method = \"loess\", se = FALSE, linetype = \"solid\", size = 1) +\n  facet_wrap(~ livch, labeller = labeller(livch = function(x) paste(\"Living Children:\", x))) +\n  scale_color_manual(values = c(\"lightblue\", \"steelblue\")) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    axis.title = element_text(face = \"bold\"),\n    strip.text = element_text(size = 12, face = \"bold\"),\n    legend.position = \"top\"\n  ) +\n  labs(\n    title = \"Contraception Usage by Age and Urbanization\",\n    x = \"Age (Years)\",\n    y = \"Contraception Use (Binary)\",\n    color = \"Urbanization\"\n  )\n\n\n\n\n\n\n\n\nThe relationship between age and contraception usage shows a distinct non-linear trend, moderated by both the number of living children and urbanization. In all panels, contraception usage increases with age, peaks, and declines in later years, forming a curved pattern. This trend is more pronounced in individuals with more living children, particularly those with 2 or 3+ children, where usage reaches higher probabilities. Urban residents (“Y”) consistently report higher contraception usage compared to their rural counterparts (“N”) across all age groups, though the gap is most noticeable among those with fewer children. The relationship remains weakest and flattest for individuals with no children, highlighting how both urbanization and family size influence the likelihood of contraception use over the life course.\n\n# Assuming Contraception is a data frame and livch is a numeric variable.\nggplot(Contraception, aes(x = factor(livch))) +\n  geom_bar(aes(fill = factor(livch)), width = 0.7) +\n  scale_fill_manual(values = c(\"steelblue\", \"lightblue\", \"skyblue\", \"lightsteelblue\", \"deepskyblue\")) +  # Customize colors close to steelblue and lightblue\n  labs(\n    title = \"Number of Living Children by Contraception Usage\",\n    x = \"Number of Living Children\",\n    y = \"Count of Individuals\",\n    fill = \"Living Children\"  # Customize legend title\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels if needed\n    plot.title = element_text(hjust = 0.5)\n  ) +\n  geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5)  # Display count on top of bars\n\n\n\n\n\n\n\n\nThe bar chart illustrates the distribution of individuals based on the number of living children, categorized into four groups: 0, 1, 2, and 3 or more children. The data indicates that the majority of individuals fall within the “3+” category, comprising 743 individuals, followed by the “0” group with 530 individuals. The categories “1” and “2” are comparatively smaller, containing 356 and 305 individuals, respectively. The counts for each group are clearly labeled, and the chart uses a gradient of blues to differentiate the categories, with darker shades representing fewer children. The visualization effectively highlights the prevalence of individuals with three or more living children in this dataset.\n\ncreate_bar_plot &lt;- function(data, x_var, x_label) {\n  ggplot(data, aes(x = .data[[x_var]], fill = factor(use_num))) + \n    geom_bar(position = \"fill\", show.legend = TRUE) +\n    labs(\n      x = x_label, \n      y = \"Proportion of Contraceptive Use\", \n      fill = \"Contraceptive Use\"\n    ) +\n    scale_fill_manual(\n      values = c(\"0\" = \"lightblue\", \"1\" = \"steelblue\"),\n      labels = c(\"No\", \"Yes\")\n    ) +\n    theme_minimal(base_size = 15) + # Larger base size for better readability\n    theme(\n      legend.position = \"top\", \n      axis.text.x = element_text(angle = 45, hjust = 1), # Rotate x-axis labels if needed\n      axis.title.x = element_text(size = 16, face = \"bold\"),  # Bigger and bolder x-title\n      axis.title.y = element_text(size = 16, face = \"bold\"),  # Bigger and bolder y-title\n      legend.title = element_text(size = 14),\n      legend.text = element_text(size = 12)\n    ) +\n    geom_text(\n      aes(label = scales::percent(..count.. / sum(..count..))),\n      stat = \"count\",\n      position = position_fill(vjust = 0.5), # Position the text in the middle of the bars\n      size = 5, color = \"white\"  # White text for contrast\n    )\n}\n\n## CONTRACEPTION  VS LIVING CHILDREN BAR PLOT\ncreate_bar_plot(Contraception, \"livch\", \"Number of Living Children\")\n\n\n\n\n\n\n\n\nThe plot is a stacked bar chart illustrating the proportion of contraceptive use (Yes vs. No) across categories of the number of living children (0, 1, 2, and 3+). Contraceptive use increases notably as the number of living children rises. For instance, in the 3+ children category, approximately 16.29% of individuals report contraceptive use, compared to 6.88% in the childless group. The trend indicates a positive association between the number of living children and the likelihood of contraceptive use, suggesting that family size may influence contraceptive decisions.\n\ncreate_box_plot &lt;- function(data) {\n  boxplot(age ~ use_num, \n          data = data, \n          xlab = \"Contraceptive Use (0 = Non-Users, 1 = Users)\", \n          ylab = \"Age (Centered)\", \n          main = \"Age Distribution by Contraceptive Use\", \n          col = c(\"lightblue\", \"steelblue\"), \n          border = \"black\", \n          notch = TRUE, \n          outline = TRUE,\n          horizontal = FALSE, \n          las = 1,  # Horizontal x-axis labels\n          cex.main = 1.5,  # Larger title\n          cex.lab = 1.2,   # Larger axis labels\n          cex.axis = 1.1,  # Larger axis ticks\n          boxwex = 0.4,    # Adjust box width\n          whisklty = 1,    # Solid whiskers\n          whiskcol = \"black\")  # Black whiskers\n  \n  # Add median line for clarity\n  abline(h = median(data$age), col = \"red\", lwd = 2, lty = 2)  # Red dashed line for median\n  \n  # Add mean points for comparison\n  points(1:2, tapply(data$age, data$use_num, mean), pch = 19, col = \"black\")  # Mean points\n  \n  # Add grid for easier comparison\n  grid(nx = NULL, ny = NULL, col = \"gray\", lty = \"dotted\")\n}\n\n# Create the box plot for age distribution\ncreate_box_plot(Contraception)\n\n\n\n\n\n\n\n\nThe first plot presents a boxplot comparing the centered age distribution between contraceptive users (coded as 1) and non-users (coded as 0). Both groups have similar median ages (approximately centered at zero), with a slight variation in spread. Non-users exhibit a broader interquartile range and greater variability, whereas contraceptive users show a more compact age range. The black dots indicate mean values, which are nearly identical for both groups. This suggests that age, while centered here, does not show a significant difference in distribution between the two categories of contraceptive use, except the heavier tails for non-users.\n\nContraception %&gt;%\n  count(district) %&gt;%\n  ggplot(aes(x = reorder(district, -n), y = n, fill = n)) +  # Map 'n' to 'fill' for color gradient\n  geom_bar(stat = \"identity\", color = \"black\", width = 0.8) +\n  scale_fill_gradient(low = \"lightblue\", high = \"steelblue\") +  # Gradient from light to dark blue\n  theme_minimal(base_size = 16) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 12),  # Larger text for better readability\n    axis.text.y = element_text(size = 12),\n    axis.title = element_text(face = \"bold\", size = 14),\n    plot.title = element_text(face = \"bold\", size = 18, hjust = 0.5),\n    legend.position = \"none\",  # Hide the legend\n    plot.margin = margin(10, 20, 10, 10)  # Add margin for better spacing\n  ) +\n  labs(\n    title = \"Count of Contraception Usage by District\",\n    x = \"District\",\n    y = \"Count\"\n  )\n\n\n\n\n\n\n\n\nThe bar chart depicts the count of contraception usage across various districts, arranged in descending order of usage frequency. The data reveals significant variability among districts, with the highest count exceeding 120 and gradually declining across the districts. The distribution demonstrates a few districts with notably high counts of contraception usage, while the majority show moderate to low levels. The chart employs a gradient of blue shades to represent the counts, enhancing the visual differentiation between districts. This visualization highlights the disparities in contraception usage across districts, suggesting potential regional differences in adoption or access.\n\n\n\nAccording to Harrell’s guidelines [@harrell] and given the current sample size, we are able to include the full number of predictor variables in the model. My approach involves a Generalized Linear Mixed Model (GLMM) with a binomial family and a logit link function (I decided to use logit link as it is easily interpretable). This model is appropriate given the binary nature of the response variable, use_num, essentially the proposed model is a logistic regression model with random effects for the variable “district” with the intercept and “urban” varying across each “district.”\nThe conditional distribution for use_num given the covariates and random effects is:\n\\[\nY_i \\mid \\mathbf{x}_i, u_i \\sim \\text{Bernoulli}\\left(\\frac{1}{1 + \\exp(-\\eta_i)}\\right)\n\\]\nwhere \\(\\eta_i\\) is the linear predictor for individual \\(i\\), incorporating both the fixed effects and the random effects for the district.\n\n\n\nCentered Age of Women (age): The first predictor is the centered age of women (using a spline for capturing the non-linear relationship of the variable age). It is hypothesized that the relationship between age and contraception use follows an inverted U-shape, with both younger and older women using contraception less frequently than those in middle age. This makes age an important predictor in the model.\nNumber of Living Children (livch): The second predictor is the number of living children. It is expected that as individuals establish stable partnerships and have children, the need for contraception may decrease. Therefore, the number of children is anticipated to influence contraception usage, justifying its inclusion as a predictor in the model.\nType of Residence (urban): The third predictor is the type of residence, which is categorized as either urban or rural. Contraception use is often linked to socio-economic factors, and urban areas tend to be wealthier and offer better educational opportunities. Higher education levels are generally associated with increased contraception use[@CanadianContraceptionConsensusChapter1ContraceptioninCanada], suggesting that the type of residence could significantly impact contraception behavior.\n\nIn this analysis, the maximal model for our problem includes random intercepts and random slopes for the urban variable, which varies across 60 districts (groups). If convergence issues or singularity problems arise, a stepwise reduction of the model will be employed, initially by removing the random slope for each urban variable. Further model modifications will be discussed if necessary based on subsequent challenges.\nFor the integration of the random effects, both the Laplace approximation and the Penalized Quasi-Likelihood (PQL) approximation will be utilized. Given that the random effects in this model are not particularly complex, both methods are expected to provide reliable, fast, and accurate results. The PQL approximation, in particular, is known for offering relatively better approximations for model withm complex random effect when the laplace approximation method struggles (but it is a bit slower), and both techniques will be applied for completeness.\nTo implement the model, I will use three packages: lme4, MASS, and brms. The lme4 package provides the glmer() function, a frequentist approach for fitting generalized linear mixed models (GLMMs). It uses the Laplace approximation, which is computationally efficient and reliable for fitting models with complex random effects structures. The advantage of using lme4 lies in its ability to handle large datasets with high dimensionality and its robustness in estimating fixed and random effects, making it an excellent choice for models with multiple predictors and random effects structures. The MASS package provides the glmmPQL() function, which is a frequentist method based on the penalized quasi-likelihood (PQL) approximation. This approach is suitable for models with non-Gaussian responses and is particularly effective when random effects have complex structures. Although less commonly used today, it remains a viable option when alternative methods, such as Laplace approximation, struggle with convergence or performance, especially in smaller datasets or when there are numerous levels of grouping factors.\nThe brms package is a Bayesian framework that fits GLMMs using Hamiltonian Monte Carlo (HMC) through Stan. This package is chosen for its flexibility in specifying complex prior distributions and its ability to provide full posterior distributions of model parameters, allowing for more nuanced inferences compared to frequentist methods. brms allows for detailed prior specification, which is important for this model, as I plan to use a combination of flat, uninformative priors for fixed effects (b), such as b (default) for livch1, livch2, livch3P, nsagedfEQ21, nsagedfEQ22, and urbanY. For the intercept, I will use a half-student-t(3, 0, 2.5) prior, as it offers heavier tails, which is beneficial in accommodating outliers or influential data points without overly constraining the model. For the random effects, I will use a half-Cauchy(0, 2.5) prior for the standard deviations (sd) of random effects, including district and intercept district, as well as the LKJ(1) prior for the correlation structure of the random effects. The half-Cauchy(0, 2.5) prior is a common choice for random effect standard deviations in hierarchical models, as it allows for flexibility while avoiding excessive shrinkage of the random effects variance. The LKJ(1) prior is used to model the correlation structure among the random effects and encourages weak correlations among random effects, which is a sensible assumption in many applied settings.\nTogether, these three packages provide a comprehensive suite for fitting GLMMs from both frequentist and Bayesian perspectives. lme4 offers a robust frequentist approach, MASS provides an alternative for complex random effects structures, and brms offers Bayesian modeling with flexible prior specifications. This combination of methods ensures a thorough comparison between frequentist and Bayesian approaches, each of which has distinct advantages depending on the nature of the data and the model.\n\n\n\n\n\n## Model 1: glmmTMB\nmodel_glmer &lt;- glmer(use_num ~ \n                         ns(age,df=2) + livch + urban + (1+urban|district), \n                         data = Contraception, \n                         family = binomial(link = \"logit\"))\n\n\n# Model 2: glmmPQL\nglmmPQL_model &lt;- MASS::glmmPQL(use_num ~ \n                               ns(age,df=2) + livch + urban, random = ~ 1+\n                               urban|district,family = binomial, data =\n                               Contraception)\n\n\n# Model 3: Bayesian Model\n\n# Define half-Cauchy priors\npriors &lt;- c(\n  prior(cauchy(0, 2.5), class = \"sd\"),            # Half-Cauchy for random effect SDs\n  prior(cauchy(0, 2.5), class = \"sd\", group = \"district\"),  # Specific to district random effects\n  prior(cauchy(0, 2.5), class = \"sd\", coef = \"urbanY\", group = \"district\") # Specific slope\n)\n\n# Update the model with new priors\nmodel_brms &lt;- brm(\n  use_num ~ ns(age, df = 2) + livch + urban + (1 + urban | district),\n  family = bernoulli(),\n  data = Contraception,\n  prior = priors\n)\n# prior_summary(model_brms)\n\n\nsummary(model_glmer)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: use_num ~ ns(age, df = 2) + livch + urban + (1 + urban | district)\n   Data: Contraception\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n   2381.6    2437.3   -1180.8    2361.6      1924 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.9469 -0.7436 -0.4449  0.9012  3.0816 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n district (Intercept) 0.3874   0.6224        \n          urbanY      0.5469   0.7395   -0.79\nNumber of obs: 1934, groups:  district, 60\n\nFixed effects:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -1.8991     0.1808 -10.503  &lt; 2e-16 ***\nns(age, df = 2)1   1.0942     0.4392   2.491   0.0127 *  \nns(age, df = 2)2  -1.2294     0.2411  -5.099 3.41e-07 ***\nlivch1             0.8314     0.1654   5.026 5.00e-07 ***\nlivch2             0.9063     0.1896   4.781 1.75e-06 ***\nlivch3+            0.9338     0.1903   4.907 9.25e-07 ***\nurbanY             0.7756     0.1643   4.720 2.36e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) n(,d=2)1 n(,d=2)2 livch1 livch2 lvch3+\nns(g,df=2)1 -0.567                                       \nns(g,df=2)2 -0.040  0.330                                \nlivch1      -0.217 -0.312   -0.065                       \nlivch2      -0.081 -0.493   -0.162    0.526              \nlivch3+     -0.026 -0.655   -0.449    0.565  0.651       \nurbanY      -0.384 -0.045   -0.029    0.051  0.076  0.076\n\nsummary(glmmPQL_model)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: Contraception \n  AIC BIC logLik\n   NA  NA     NA\n\nRandom effects:\n Formula: ~1 + urban | district\n Structure: General positive-definite, Log-Cholesky parametrization\n            StdDev    Corr  \n(Intercept) 0.6127317 (Intr)\nurbanY      0.7392394 -0.788\nResidual    0.9755972       \n\nVariance function:\n Structure: fixed weights\n Formula: ~invwt \nFixed effects:  use_num ~ ns(age, df = 2) + livch + urban \n                      Value Std.Error   DF    t-value p-value\n(Intercept)      -1.8499396 0.1745571 1868 -10.597905  0.0000\nns(age, df = 2)1  1.0675016 0.4251999 1868   2.510588  0.0121\nns(age, df = 2)2 -1.1977196 0.2326712 1868  -5.147693  0.0000\nlivch1            0.8124300 0.1598835 1868   5.081386  0.0000\nlivch2            0.8843755 0.1832614 1868   4.825760  0.0000\nlivch3+           0.9124638 0.1835004 1868   4.972544  0.0000\nurbanY            0.7529924 0.1593175 1868   4.726363  0.0000\n Correlation: \n                 (Intr) n(,d=2)1 n(,d=2)2 livch1 livch2 lvch3+\nns(age, df = 2)1 -0.569                                       \nns(age, df = 2)2 -0.050  0.332                                \nlivch1           -0.215 -0.312   -0.063                       \nlivch2           -0.077 -0.493   -0.159    0.527              \nlivch3+          -0.017 -0.658   -0.445    0.565  0.651       \nurbanY           -0.393 -0.042   -0.031    0.047  0.077  0.075\n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-1.9857276 -0.7643117 -0.4595243  0.9260949  3.1084571 \n\nNumber of Observations: 1934\nNumber of Groups: 60 \n\nsummary(model_brms)\n\n Family: bernoulli \n  Links: mu = logit \nFormula: use_num ~ ns(age, df = 2) + livch + urban + (1 + urban | district) \n   Data: Contraception (Number of observations: 1934) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~district (Number of levels: 60) \n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)             0.64      0.11     0.44     0.88 1.00     1443\nsd(urbanY)                0.77      0.23     0.34     1.24 1.00      864\ncor(Intercept,urbanY)    -0.69      0.17    -0.92    -0.29 1.00     1849\n                      Tail_ESS\nsd(Intercept)             2331\nsd(urbanY)                1118\ncor(Intercept,urbanY)     2503\n\nRegression Coefficients:\n            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      -1.91      0.18    -2.28    -1.55 1.00     4130     3146\nnsagedfEQ21     1.11      0.43     0.26     1.97 1.00     3456     2980\nnsagedfEQ22    -1.24      0.24    -1.72    -0.77 1.00     5374     2644\nlivch1          0.84      0.16     0.52     1.14 1.00     4140     3348\nlivch2          0.91      0.19     0.54     1.27 1.00     3272     3214\nlivch3P         0.94      0.19     0.59     1.31 1.00     2682     2745\nurbanY          0.76      0.17     0.43     1.11 1.00     2784     2631\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nAfter fitting the models using different packages, we did not encounter any convergence or singularity issues. Consequently, we will proceed with the analysis based on the initial model. Should any issues arise during the diagnostic checks, we will consider making necessary adjustments to the model.\n\n\n\n\nresiduals_dharma &lt;- simulateResiduals(model_glmer)\n# Plot the residuals\nplot(residuals_dharma)\n\n\n\n\n\n\n\nperformance::check_model(model_glmer, panel = TRUE)\n\n\n\n\n\n\n\n\nThe diagnostic plots assess the fit and assumptions of the model. The first set of plots, generated using DHARMa, shows that residual diagnostics do not indicate significant issues. The QQ plot demonstrates that observed residuals align well with expectations under the fitted model, as evidenced by the nonsignificant Kolmogorov-Smirnov test (p = 0.87215). Furthermore, dispersion and outlier tests also fail to detect deviations, suggesting no overdispersion or extreme values affecting the model fit. The residual vs. predicted plot confirms that residuals are evenly distributed across predicted values without systematic patterns, indicating an appropriate functional form for the predictors.\nThe second set of diagnostics provides further insights. The posterior predictive check shows observed and model-predicted distributions closely matching, supporting the adequacy of the model. Binned residuals mostly fall within error bounds, except for minor deviations, which may warrant attention. The VIF values for predictors are well below 5, indicating no concerning multicollinearity. Influential observations appear within acceptable ranges on the leverage plot, and the residual uniformity aligns with theoretical expectations. Random effects also display normality, as indicated by quantile plots, reinforcing the validity of the random structure. Together, these diagnostics suggest the model is well-specified, with only minor areas for potential refinement.\nHence, there is no need for any changes to our model, and we could say that it is adequate for the above problem.\n\n\n\n\nmodel_glmer_scaled &lt;- glmer(use_num ~ \n                         ns(scale(age),df=2) + livch + urban + (1+urban|district), \n                         data = Contraception, \n                         family = binomial(link = \"logit\"))\n\nsjPlot::plot_model(model_glmer_scaled, type = \"est\", show.values = TRUE, show.p = TRUE,\n                   title = \"Coefficient Plot for Mixed-Effects Logistic Regression using lme4\")\n\n\n\n\n\n\n\n\nThe coefficient plot illustrates the odds ratios for predictors in a mixed-effects logistic regression model. Each point represents the odds ratio for a predictor, with horizontal lines denoting the corresponding 95% confidence intervals. Significant predictors are marked with asterisks indicating their level of significance (*p &lt; 0.05, **p &lt; 0.01, ***p &lt; 0.001). The “scale” variable has two components: one showing a significant positive effect (OR = 2.99, p &lt; 0.05) and the other a significant negative effect (OR = 0.29, p &lt; 0.001). The categorical variable “livch” exhibits increasing odds ratios across levels, with the highest level (3+) having an OR of 2.54 (p &lt; 0.001). The variable “urban [Y]” is also significantly associated with the outcome (OR = 2.17, p &lt; 0.001), indicating that urban residency increases the odds of the modeled outcome. These results demonstrate the importance of these predictors in explaining variability in the response variable.\n\nBellow, I will also provide coefficient plots of the other methods, but the interpretation remains the same (for completeness).\n\nglmmPQL_model_scaled &lt;- MASS::glmmPQL(use_num ~ \n                               ns(scale(age),df=2) + livch + urban, random = ~ 1+\n                               urban|district,family = binomial, data =\n                               Contraception)\n\nsjPlot::plot_model(glmmPQL_model_scaled, type = \"est\", show.values = TRUE, show.p = TRUE,\n                   title = \"Coefficient Plot for Mixed-Effects Logistic Regression using MASS (PQL)\")\n\n\n\n\n\n\n\n\nand for the Bayesian model:\n\nsjPlot::plot_model(glmmPQL_model_scaled, type = \"est\", show.values = TRUE, show.p = TRUE,\n                   title = \"Coefficient Plot for Mixed-Effects Logistic Regression using brms\")\n\n\n\n\n\n\n\n\nNow, for the effects plots I will only provide the effect plot from the model using lme4, as they are identical.\n\n# Plot the effects of the model\nplot(allEffects(model_glmer), main = \"Effects of Predictors on Contraception Use\")\n\n\n\n\n\n\n\n\nThe set of plots illustrates the effects of three predictors—age, number of living children (livch), and urban residency (urban)—on contraception use, based on model estimates. The first plot shows a non-linear relationship between age and contraception use, with usage peaking around the middle age range and decreasing at both younger and older ages. The shaded area represents the 95% confidence interval for the predicted values. The second plot highlights a positive association between the number of living children and contraception use, where usage increases significantly from 0 to 3+ children, stabilizing for the highest category. The third plot compares contraception use between urban and non-urban residents, indicating higher usage among urban residents, with error bars denoting the confidence intervals. These findings suggest that all three predictors—age, livch, and urban—significantly influence contraception use patterns.\n\n\n\n\nmodels_list &lt;- list(\n  model_glmer = model_glmer,\n  glmmPQL_model = glmmPQL_model,\n  model_brms = model_brms\n)\n\n# Extract and arrange fixed effect coefficients for comparison\nfixed_effects_comparison &lt;- purrr::map_dfr(models_list, ~tidy(., effects = \"fixed\", conf.int=TRUE), .id = \"model\") |&gt;\n  dplyr::arrange(term)\n\n# View the comparison\nfixed_effects_comparison[12,3] &lt;- \"livch3+\"\nfixed_effects_comparison[17,3] &lt;- \"ns(age, df = 2)1\"\nfixed_effects_comparison[18,3] &lt;- \"ns(age, df = 2)2\"\nhead(fixed_effects_comparison)\n\n# A tibble: 6 × 11\n  model   effect term  estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 model_… fixed  (Int…   -1.90      0.181    -10.5   8.33e-26   -2.25      -1.54\n2 glmmPQ… fixed  (Int…   -1.85      0.175    -10.6   1.59e-25   -2.19      -1.51\n3 model_… fixed  (Int…   -1.91      0.184     NA    NA          -2.28      -1.55\n4 model_… fixed  livc…    0.831     0.165      5.03  5.00e- 7    0.507      1.16\n5 glmmPQ… fixed  livc…    0.812     0.160      5.08  4.12e- 7    0.499      1.13\n6 model_… fixed  livc…    0.836     0.160     NA    NA           0.522      1.14\n# ℹ 2 more variables: df &lt;dbl&gt;, component &lt;chr&gt;\n\n# Plot fixed effects using ggplot2\nggplot(fixed_effects_comparison, aes(x = estimate, y = model, color = model)) +\n  geom_point() +\n  geom_errorbarh(aes(xmin = estimate - std.error, xmax = estimate + std.error), height = 0.2) +\n  facet_wrap(~term, scales = \"free\") +\n  labs(title = \"Coefficient Plot of Fixed Effects\",\n       x = \"Estimate\",\n       y = \"Model\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe coefficient plot visualizes fixed-effect estimates for three different models: model_glmer, model_brms, and glmmPQL_model, across predictors including natural splines for age (ns(age, df=2)), number of living children (livch1, livch2, livch3+), and urban residency (urbanY). The plot demonstrates that the models produce consistent estimates with overlapping confidence intervals for most predictors, particularly for model_glmer and model_brms, which align closely. In contrast, glmmPQL_model exhibits more variability and narrower confidence intervals, diverging slightly for some coefficients. Notably, the Intercept and ns(age, df=2)[2] show a greater disparity between glmmPQL_model and the other two. These differences may reflect methodological variances in estimation techniques, underscoring the importance of model selection based on context and assumptions.\nPenalized Quasi-Likelihood (PQL) can be a valuable tool, especially in specific situations like smaller datasets, complex random effects structures, or when other methods face convergence challenges. However, the differences observed in your coefficient plot suggest that the divergence of glmmPQL_model from glmer and brms may stem from known limitations of the PQL approach, even within its intended use cases.\nPQL’s iterative nature and reliance on linearization at each step make it sensitive to the complexity of the model and the scale of the data. For example, in models with highly nonlinear relationships (such as those involving natural splines for age), the approximation process can lead to biased fixed-effect estimates. Furthermore, its point estimates might differ more noticeably when the sample size is small, as it does not fully maximize or integrate the likelihood like glmer or brms.\nWhile PQL is robust in avoiding convergence issues where likelihood-based methods might struggle, its performance might trade off precision or accuracy in parameter estimation. The observed discrepancies in your plot could therefore highlight the method’s limitations in fully capturing the variability or structure of the data compared to the more modern and computationally intensive approaches like maximum likelihood or Bayesian estimation.\nThis does not discredit PQL as a method but rather emphasizes its situational utility. In our case, it may be worth investigating whether data characteristics (e.g., the number of grouping levels or the distribution of the response variable) align with PQL’s strengths, or if model simplification could alleviate convergence issues in glmer or brms."
  },
  {
    "objectID": "Project_5.html#data-visualization",
    "href": "Project_5.html#data-visualization",
    "title": "Project 5",
    "section": "Data Visualization",
    "text": "Data Visualization\nBefore specifying the modeling process, it is essential to visually explore the data to gain valuable insights into its structure, relationships, and patterns. Graphical representations allow for an intuitive understanding of the data’s key features, enabling informed decisions about the modeling strategy, potential transformations, and variable selection. This step provides a foundation for identifying trends, outliers, and potential interactions, which are crucial for constructing effective and interpretable models.\n\nggplot(Contraception, aes(x = age, y = use_num)) +\n  geom_jitter(\n    height = 0.05, width = 0, alpha = 0.4, size = 1.5, color = \"lightblue\"\n  ) + \n  geom_smooth(\n    method = \"loess\", color = \"steelblue\", se = TRUE, linewidth = 1.2, span = 0.8, formula = 'y~x'\n  ) +\n  scale_y_continuous(\n    breaks = c(0, 1),\n    labels = c(\"Not Using\", \"Using\")\n  ) +\n  labs(\n    title = \"Contraception Usage vs Age\",\n    subtitle = \"Smoothed trend with jittered raw data points\",\n    x = \"Age (in years)\", \n    y = \"Contraception Usage\"\n  ) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    plot.subtitle = element_text(hjust = 0.5),\n    panel.grid.minor = element_blank()\n  )\n\n\n\n\n\n\n\n\nThe relationship between age and contraception usage exhibits a clear non-linear trend, as shown in the graph. Contraception usage increases with age during younger adulthood, peaks at mid-range ages, and then declines in older age, forming a curved pattern. This suggests that individuals in middle age are more likely to use contraception compared to younger or older individuals. The jittered raw data points highlight the binary nature of the response (“Using” vs. “Not Using”), with more individuals in the “Not Using” category at both age extremes. The shaded confidence interval around the smoothed trend line reflects greater variability at the younger and older ends of the age spectrum, reinforcing the need for targeted analysis when considering age-related contraception usage trends.\n\nggplot(Contraception, aes(x = age, y = use_num, color = urban)) +\n  geom_jitter(alpha = 0.4, width = 0.3, height = 0.05, size = 1.5) +\n  geom_smooth(method = \"loess\", se = FALSE, linetype = \"solid\", size = 1) +\n  facet_wrap(~ livch, labeller = labeller(livch = function(x) paste(\"Living Children:\", x))) +\n  scale_color_manual(values = c(\"lightblue\", \"steelblue\")) +\n  theme_minimal(base_size = 14) +\n  theme(\n    plot.title = element_text(face = \"bold\", size = 16, hjust = 0.5),\n    axis.title = element_text(face = \"bold\"),\n    strip.text = element_text(size = 12, face = \"bold\"),\n    legend.position = \"top\"\n  ) +\n  labs(\n    title = \"Contraception Usage by Age and Urbanization\",\n    x = \"Age (Years)\",\n    y = \"Contraception Use (Binary)\",\n    color = \"Urbanization\"\n  )\n\n\n\n\n\n\n\n\nThe relationship between age and contraception usage shows a distinct non-linear trend, moderated by both the number of living children and urbanization. In all panels, contraception usage increases with age, peaks, and declines in later years, forming a curved pattern. This trend is more pronounced in individuals with more living children, particularly those with 2 or 3+ children, where usage reaches higher probabilities. Urban residents (“Y”) consistently report higher contraception usage compared to their rural counterparts (“N”) across all age groups, though the gap is most noticeable among those with fewer children. The relationship remains weakest and flattest for individuals with no children, highlighting how both urbanization and family size influence the likelihood of contraception use over the life course.\n\n# Assuming Contraception is a data frame and livch is a numeric variable.\nggplot(Contraception, aes(x = factor(livch))) +\n  geom_bar(aes(fill = factor(livch)), width = 0.7) +\n  scale_fill_manual(values = c(\"steelblue\", \"lightblue\", \"skyblue\", \"lightsteelblue\", \"deepskyblue\")) +  # Customize colors close to steelblue and lightblue\n  labs(\n    title = \"Number of Living Children by Contraception Usage\",\n    x = \"Number of Living Children\",\n    y = \"Count of Individuals\",\n    fill = \"Living Children\"  # Customize legend title\n  ) +\n  theme_minimal() +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1),  # Rotate x-axis labels if needed\n    plot.title = element_text(hjust = 0.5)\n  ) +\n  geom_text(stat = 'count', aes(label = ..count..), vjust = -0.5)  # Display count on top of bars\n\n\n\n\n\n\n\n\nThe bar chart illustrates the distribution of individuals based on the number of living children, categorized into four groups: 0, 1, 2, and 3 or more children. The data indicates that the majority of individuals fall within the “3+” category, comprising 743 individuals, followed by the “0” group with 530 individuals. The categories “1” and “2” are comparatively smaller, containing 356 and 305 individuals, respectively. The counts for each group are clearly labeled, and the chart uses a gradient of blues to differentiate the categories, with darker shades representing fewer children. The visualization effectively highlights the prevalence of individuals with three or more living children in this dataset.\n\ncreate_bar_plot &lt;- function(data, x_var, x_label) {\n  ggplot(data, aes(x = .data[[x_var]], fill = factor(use_num))) + \n    geom_bar(position = \"fill\", show.legend = TRUE) +\n    labs(\n      x = x_label, \n      y = \"Proportion of Contraceptive Use\", \n      fill = \"Contraceptive Use\"\n    ) +\n    scale_fill_manual(\n      values = c(\"0\" = \"lightblue\", \"1\" = \"steelblue\"),\n      labels = c(\"No\", \"Yes\")\n    ) +\n    theme_minimal(base_size = 15) + # Larger base size for better readability\n    theme(\n      legend.position = \"top\", \n      axis.text.x = element_text(angle = 45, hjust = 1), # Rotate x-axis labels if needed\n      axis.title.x = element_text(size = 16, face = \"bold\"),  # Bigger and bolder x-title\n      axis.title.y = element_text(size = 16, face = \"bold\"),  # Bigger and bolder y-title\n      legend.title = element_text(size = 14),\n      legend.text = element_text(size = 12)\n    ) +\n    geom_text(\n      aes(label = scales::percent(..count.. / sum(..count..))),\n      stat = \"count\",\n      position = position_fill(vjust = 0.5), # Position the text in the middle of the bars\n      size = 5, color = \"white\"  # White text for contrast\n    )\n}\n\n## CONTRACEPTION  VS LIVING CHILDREN BAR PLOT\ncreate_bar_plot(Contraception, \"livch\", \"Number of Living Children\")\n\n\n\n\n\n\n\n\nThe plot is a stacked bar chart illustrating the proportion of contraceptive use (Yes vs. No) across categories of the number of living children (0, 1, 2, and 3+). Contraceptive use increases notably as the number of living children rises. For instance, in the 3+ children category, approximately 16.29% of individuals report contraceptive use, compared to 6.88% in the childless group. The trend indicates a positive association between the number of living children and the likelihood of contraceptive use, suggesting that family size may influence contraceptive decisions.\n\ncreate_box_plot &lt;- function(data) {\n  boxplot(age ~ use_num, \n          data = data, \n          xlab = \"Contraceptive Use (0 = Non-Users, 1 = Users)\", \n          ylab = \"Age (Centered)\", \n          main = \"Age Distribution by Contraceptive Use\", \n          col = c(\"lightblue\", \"steelblue\"), \n          border = \"black\", \n          notch = TRUE, \n          outline = TRUE,\n          horizontal = FALSE, \n          las = 1,  # Horizontal x-axis labels\n          cex.main = 1.5,  # Larger title\n          cex.lab = 1.2,   # Larger axis labels\n          cex.axis = 1.1,  # Larger axis ticks\n          boxwex = 0.4,    # Adjust box width\n          whisklty = 1,    # Solid whiskers\n          whiskcol = \"black\")  # Black whiskers\n  \n  # Add median line for clarity\n  abline(h = median(data$age), col = \"red\", lwd = 2, lty = 2)  # Red dashed line for median\n  \n  # Add mean points for comparison\n  points(1:2, tapply(data$age, data$use_num, mean), pch = 19, col = \"black\")  # Mean points\n  \n  # Add grid for easier comparison\n  grid(nx = NULL, ny = NULL, col = \"gray\", lty = \"dotted\")\n}\n\n# Create the box plot for age distribution\ncreate_box_plot(Contraception)\n\n\n\n\n\n\n\n\nThe first plot presents a boxplot comparing the centered age distribution between contraceptive users (coded as 1) and non-users (coded as 0). Both groups have similar median ages (approximately centered at zero), with a slight variation in spread. Non-users exhibit a broader interquartile range and greater variability, whereas contraceptive users show a more compact age range. The black dots indicate mean values, which are nearly identical for both groups. This suggests that age, while centered here, does not show a significant difference in distribution between the two categories of contraceptive use, except the heavier tails for non-users.\n\nContraception %&gt;%\n  count(district) %&gt;%\n  ggplot(aes(x = reorder(district, -n), y = n, fill = n)) +  # Map 'n' to 'fill' for color gradient\n  geom_bar(stat = \"identity\", color = \"black\", width = 0.8) +\n  scale_fill_gradient(low = \"lightblue\", high = \"steelblue\") +  # Gradient from light to dark blue\n  theme_minimal(base_size = 16) +\n  theme(\n    axis.text.x = element_text(angle = 45, hjust = 1, size = 12),  # Larger text for better readability\n    axis.text.y = element_text(size = 12),\n    axis.title = element_text(face = \"bold\", size = 14),\n    plot.title = element_text(face = \"bold\", size = 18, hjust = 0.5),\n    legend.position = \"none\",  # Hide the legend\n    plot.margin = margin(10, 20, 10, 10)  # Add margin for better spacing\n  ) +\n  labs(\n    title = \"Count of Contraception Usage by District\",\n    x = \"District\",\n    y = \"Count\"\n  )\n\n\n\n\n\n\n\n\nThe bar chart depicts the count of contraception usage across various districts, arranged in descending order of usage frequency. The data reveals significant variability among districts, with the highest count exceeding 120 and gradually declining across the districts. The distribution demonstrates a few districts with notably high counts of contraception usage, while the majority show moderate to low levels. The chart employs a gradient of blue shades to represent the counts, enhancing the visual differentiation between districts. This visualization highlights the disparities in contraception usage across districts, suggesting potential regional differences in adoption or access."
  },
  {
    "objectID": "Project_5.html#modeling-strategy",
    "href": "Project_5.html#modeling-strategy",
    "title": "Project 5",
    "section": "Modeling Strategy",
    "text": "Modeling Strategy\nAccording to Harrell’s guidelines [@harrell] and given the current sample size, we are able to include the full number of predictor variables in the model. My approach involves a Generalized Linear Mixed Model (GLMM) with a binomial family and a logit link function (I decided to use logit link as it is easily interpretable). This model is appropriate given the binary nature of the response variable, use_num, essentially the proposed model is a logistic regression model with random effects for the variable “district” with the intercept and “urban” varying across each “district.”\nThe conditional distribution for use_num given the covariates and random effects is:\n\\[\nY_i \\mid \\mathbf{x}_i, u_i \\sim \\text{Bernoulli}\\left(\\frac{1}{1 + \\exp(-\\eta_i)}\\right)\n\\]\nwhere \\(\\eta_i\\) is the linear predictor for individual \\(i\\), incorporating both the fixed effects and the random effects for the district.\n\nFixed Effects\n\nCentered Age of Women (age): The first predictor is the centered age of women (using a spline for capturing the non-linear relationship of the variable age). It is hypothesized that the relationship between age and contraception use follows an inverted U-shape, with both younger and older women using contraception less frequently than those in middle age. This makes age an important predictor in the model.\nNumber of Living Children (livch): The second predictor is the number of living children. It is expected that as individuals establish stable partnerships and have children, the need for contraception may decrease. Therefore, the number of children is anticipated to influence contraception usage, justifying its inclusion as a predictor in the model.\nType of Residence (urban): The third predictor is the type of residence, which is categorized as either urban or rural. Contraception use is often linked to socio-economic factors, and urban areas tend to be wealthier and offer better educational opportunities. Higher education levels are generally associated with increased contraception use[@CanadianContraceptionConsensusChapter1ContraceptioninCanada], suggesting that the type of residence could significantly impact contraception behavior.\n\nIn this analysis, the maximal model for our problem includes random intercepts and random slopes for the urban variable, which varies across 60 districts (groups). If convergence issues or singularity problems arise, a stepwise reduction of the model will be employed, initially by removing the random slope for each urban variable. Further model modifications will be discussed if necessary based on subsequent challenges.\nFor the integration of the random effects, both the Laplace approximation and the Penalized Quasi-Likelihood (PQL) approximation will be utilized. Given that the random effects in this model are not particularly complex, both methods are expected to provide reliable, fast, and accurate results. The PQL approximation, in particular, is known for offering relatively better approximations for model withm complex random effect when the laplace approximation method struggles (but it is a bit slower), and both techniques will be applied for completeness.\nTo implement the model, I will use three packages: lme4, MASS, and brms. The lme4 package provides the glmer() function, a frequentist approach for fitting generalized linear mixed models (GLMMs). It uses the Laplace approximation, which is computationally efficient and reliable for fitting models with complex random effects structures. The advantage of using lme4 lies in its ability to handle large datasets with high dimensionality and its robustness in estimating fixed and random effects, making it an excellent choice for models with multiple predictors and random effects structures. The MASS package provides the glmmPQL() function, which is a frequentist method based on the penalized quasi-likelihood (PQL) approximation. This approach is suitable for models with non-Gaussian responses and is particularly effective when random effects have complex structures. Although less commonly used today, it remains a viable option when alternative methods, such as Laplace approximation, struggle with convergence or performance, especially in smaller datasets or when there are numerous levels of grouping factors.\nThe brms package is a Bayesian framework that fits GLMMs using Hamiltonian Monte Carlo (HMC) through Stan. This package is chosen for its flexibility in specifying complex prior distributions and its ability to provide full posterior distributions of model parameters, allowing for more nuanced inferences compared to frequentist methods. brms allows for detailed prior specification, which is important for this model, as I plan to use a combination of flat, uninformative priors for fixed effects (b), such as b (default) for livch1, livch2, livch3P, nsagedfEQ21, nsagedfEQ22, and urbanY. For the intercept, I will use a half-student-t(3, 0, 2.5) prior, as it offers heavier tails, which is beneficial in accommodating outliers or influential data points without overly constraining the model. For the random effects, I will use a half-Cauchy(0, 2.5) prior for the standard deviations (sd) of random effects, including district and intercept district, as well as the LKJ(1) prior for the correlation structure of the random effects. The half-Cauchy(0, 2.5) prior is a common choice for random effect standard deviations in hierarchical models, as it allows for flexibility while avoiding excessive shrinkage of the random effects variance. The LKJ(1) prior is used to model the correlation structure among the random effects and encourages weak correlations among random effects, which is a sensible assumption in many applied settings.\nTogether, these three packages provide a comprehensive suite for fitting GLMMs from both frequentist and Bayesian perspectives. lme4 offers a robust frequentist approach, MASS provides an alternative for complex random effects structures, and brms offers Bayesian modeling with flexible prior specifications. This combination of methods ensures a thorough comparison between frequentist and Bayesian approaches, each of which has distinct advantages depending on the nature of the data and the model."
  },
  {
    "objectID": "Project_5.html#model-fit",
    "href": "Project_5.html#model-fit",
    "title": "Project 5",
    "section": "Model Fit",
    "text": "Model Fit\n\n## Model 1: glmmTMB\nmodel_glmer &lt;- glmer(use_num ~ \n                         ns(age,df=2) + livch + urban + (1+urban|district), \n                         data = Contraception, \n                         family = binomial(link = \"logit\"))\n\n\n# Model 2: glmmPQL\nglmmPQL_model &lt;- MASS::glmmPQL(use_num ~ \n                               ns(age,df=2) + livch + urban, random = ~ 1+\n                               urban|district,family = binomial, data =\n                               Contraception)\n\n\n# Model 3: Bayesian Model\n\n# Define half-Cauchy priors\npriors &lt;- c(\n  prior(cauchy(0, 2.5), class = \"sd\"),            # Half-Cauchy for random effect SDs\n  prior(cauchy(0, 2.5), class = \"sd\", group = \"district\"),  # Specific to district random effects\n  prior(cauchy(0, 2.5), class = \"sd\", coef = \"urbanY\", group = \"district\") # Specific slope\n)\n\n# Update the model with new priors\nmodel_brms &lt;- brm(\n  use_num ~ ns(age, df = 2) + livch + urban + (1 + urban | district),\n  family = bernoulli(),\n  data = Contraception,\n  prior = priors\n)\n# prior_summary(model_brms)\n\n\nsummary(model_glmer)\n\nGeneralized linear mixed model fit by maximum likelihood (Laplace\n  Approximation) [glmerMod]\n Family: binomial  ( logit )\nFormula: use_num ~ ns(age, df = 2) + livch + urban + (1 + urban | district)\n   Data: Contraception\n\n      AIC       BIC    logLik -2*log(L)  df.resid \n   2381.6    2437.3   -1180.8    2361.6      1924 \n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-1.9469 -0.7436 -0.4449  0.9012  3.0816 \n\nRandom effects:\n Groups   Name        Variance Std.Dev. Corr \n district (Intercept) 0.3874   0.6224        \n          urbanY      0.5469   0.7395   -0.79\nNumber of obs: 1934, groups:  district, 60\n\nFixed effects:\n                 Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept)       -1.8991     0.1808 -10.503  &lt; 2e-16 ***\nns(age, df = 2)1   1.0942     0.4392   2.491   0.0127 *  \nns(age, df = 2)2  -1.2294     0.2411  -5.099 3.41e-07 ***\nlivch1             0.8314     0.1654   5.026 5.00e-07 ***\nlivch2             0.9063     0.1896   4.781 1.75e-06 ***\nlivch3+            0.9338     0.1903   4.907 9.25e-07 ***\nurbanY             0.7756     0.1643   4.720 2.36e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nCorrelation of Fixed Effects:\n            (Intr) n(,d=2)1 n(,d=2)2 livch1 livch2 lvch3+\nns(g,df=2)1 -0.567                                       \nns(g,df=2)2 -0.040  0.330                                \nlivch1      -0.217 -0.312   -0.065                       \nlivch2      -0.081 -0.493   -0.162    0.526              \nlivch3+     -0.026 -0.655   -0.449    0.565  0.651       \nurbanY      -0.384 -0.045   -0.029    0.051  0.076  0.076\n\nsummary(glmmPQL_model)\n\nLinear mixed-effects model fit by maximum likelihood\n  Data: Contraception \n  AIC BIC logLik\n   NA  NA     NA\n\nRandom effects:\n Formula: ~1 + urban | district\n Structure: General positive-definite, Log-Cholesky parametrization\n            StdDev    Corr  \n(Intercept) 0.6127317 (Intr)\nurbanY      0.7392394 -0.788\nResidual    0.9755972       \n\nVariance function:\n Structure: fixed weights\n Formula: ~invwt \nFixed effects:  use_num ~ ns(age, df = 2) + livch + urban \n                      Value Std.Error   DF    t-value p-value\n(Intercept)      -1.8499396 0.1745571 1868 -10.597905  0.0000\nns(age, df = 2)1  1.0675016 0.4251999 1868   2.510588  0.0121\nns(age, df = 2)2 -1.1977196 0.2326712 1868  -5.147693  0.0000\nlivch1            0.8124300 0.1598835 1868   5.081386  0.0000\nlivch2            0.8843755 0.1832614 1868   4.825760  0.0000\nlivch3+           0.9124638 0.1835004 1868   4.972544  0.0000\nurbanY            0.7529924 0.1593175 1868   4.726363  0.0000\n Correlation: \n                 (Intr) n(,d=2)1 n(,d=2)2 livch1 livch2 lvch3+\nns(age, df = 2)1 -0.569                                       \nns(age, df = 2)2 -0.050  0.332                                \nlivch1           -0.215 -0.312   -0.063                       \nlivch2           -0.077 -0.493   -0.159    0.527              \nlivch3+          -0.017 -0.658   -0.445    0.565  0.651       \nurbanY           -0.393 -0.042   -0.031    0.047  0.077  0.075\n\nStandardized Within-Group Residuals:\n       Min         Q1        Med         Q3        Max \n-1.9857276 -0.7643117 -0.4595243  0.9260949  3.1084571 \n\nNumber of Observations: 1934\nNumber of Groups: 60 \n\nsummary(model_brms)\n\n Family: bernoulli \n  Links: mu = logit \nFormula: use_num ~ ns(age, df = 2) + livch + urban + (1 + urban | district) \n   Data: Contraception (Number of observations: 1934) \n  Draws: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;\n         total post-warmup draws = 4000\n\nMultilevel Hyperparameters:\n~district (Number of levels: 60) \n                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS\nsd(Intercept)             0.64      0.10     0.45     0.87 1.01     1240\nsd(urbanY)                0.76      0.22     0.35     1.20 1.01      876\ncor(Intercept,urbanY)    -0.70      0.16    -0.92    -0.30 1.00     1715\n                      Tail_ESS\nsd(Intercept)             1946\nsd(urbanY)                1046\ncor(Intercept,urbanY)     2127\n\nRegression Coefficients:\n            Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept      -1.91      0.18    -2.26    -1.55 1.00     3049     3296\nnsagedfEQ21     1.10      0.44     0.25     1.96 1.00     2761     3194\nnsagedfEQ22    -1.24      0.25    -1.73    -0.76 1.00     3963     3269\nlivch1          0.84      0.16     0.52     1.15 1.00     3235     3102\nlivch2          0.91      0.19     0.55     1.29 1.00     2462     2820\nlivch3P         0.94      0.19     0.58     1.31 1.00     1955     2423\nurbanY          0.78      0.17     0.44     1.12 1.00     2257     2781\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n\n\nAfter fitting the models using different packages, we did not encounter any convergence or singularity issues. Consequently, we will proceed with the analysis based on the initial model. Should any issues arise during the diagnostic checks, we will consider making necessary adjustments to the model."
  },
  {
    "objectID": "Project_5.html#diagnostics",
    "href": "Project_5.html#diagnostics",
    "title": "Project 5",
    "section": "Diagnostics",
    "text": "Diagnostics\n\nresiduals_dharma &lt;- simulateResiduals(model_glmer)\n# Plot the residuals\nplot(residuals_dharma)\n\n\n\n\n\n\n\nperformance::check_model(model_glmer, panel = TRUE)\n\n\n\n\n\n\n\n\nThe diagnostic plots assess the fit and assumptions of the model. The first set of plots, generated using DHARMa, shows that residual diagnostics do not indicate significant issues. The QQ plot demonstrates that observed residuals align well with expectations under the fitted model, as evidenced by the nonsignificant Kolmogorov-Smirnov test (p = 0.87215). Furthermore, dispersion and outlier tests also fail to detect deviations, suggesting no overdispersion or extreme values affecting the model fit. The residual vs. predicted plot confirms that residuals are evenly distributed across predicted values without systematic patterns, indicating an appropriate functional form for the predictors.\nThe second set of diagnostics provides further insights. The posterior predictive check shows observed and model-predicted distributions closely matching, supporting the adequacy of the model. Binned residuals mostly fall within error bounds, except for minor deviations, which may warrant attention. The VIF values for predictors are well below 5, indicating no concerning multicollinearity. Influential observations appear within acceptable ranges on the leverage plot, and the residual uniformity aligns with theoretical expectations. Random effects also display normality, as indicated by quantile plots, reinforcing the validity of the random structure. Together, these diagnostics suggest the model is well-specified, with only minor areas for potential refinement.\nHence, there is no need for any changes to our model, and we could say that it is adequate for the above problem."
  },
  {
    "objectID": "Project_5.html#coefficient-plots-and-effects-plots",
    "href": "Project_5.html#coefficient-plots-and-effects-plots",
    "title": "Project 5",
    "section": "Coefficient Plots and Effects Plots",
    "text": "Coefficient Plots and Effects Plots\n\nmodel_glmer_scaled &lt;- glmer(use_num ~ \n                         ns(scale(age),df=2) + livch + urban + (1+urban|district), \n                         data = Contraception, \n                         family = binomial(link = \"logit\"))\n\nsjPlot::plot_model(model_glmer_scaled, type = \"est\", show.values = TRUE, show.p = TRUE,\n                   title = \"Coefficient Plot for Mixed-Effects Logistic Regression using lme4\")\n\n\n\n\n\n\n\n\nThe coefficient plot illustrates the odds ratios for predictors in a mixed-effects logistic regression model. Each point represents the odds ratio for a predictor, with horizontal lines denoting the corresponding 95% confidence intervals. Significant predictors are marked with asterisks indicating their level of significance (*p &lt; 0.05, **p &lt; 0.01, ***p &lt; 0.001). The “scale” variable has two components: one showing a significant positive effect (OR = 2.99, p &lt; 0.05) and the other a significant negative effect (OR = 0.29, p &lt; 0.001). The categorical variable “livch” exhibits increasing odds ratios across levels, with the highest level (3+) having an OR of 2.54 (p &lt; 0.001). The variable “urban [Y]” is also significantly associated with the outcome (OR = 2.17, p &lt; 0.001), indicating that urban residency increases the odds of the modeled outcome. These results demonstrate the importance of these predictors in explaining variability in the response variable.\n\nBellow, I will also provide coefficient plots of the other methods, but the interpretation remains the same (for completeness).\n\nglmmPQL_model_scaled &lt;- MASS::glmmPQL(use_num ~ \n                               ns(scale(age),df=2) + livch + urban, random = ~ 1+\n                               urban|district,family = binomial, data =\n                               Contraception)\n\nsjPlot::plot_model(glmmPQL_model_scaled, type = \"est\", show.values = TRUE, show.p = TRUE,\n                   title = \"Coefficient Plot for Mixed-Effects Logistic Regression using MASS (PQL)\")\n\n\n\n\n\n\n\n\nand for the Bayesian model:\n\nsjPlot::plot_model(glmmPQL_model_scaled, type = \"est\", show.values = TRUE, show.p = TRUE,\n                   title = \"Coefficient Plot for Mixed-Effects Logistic Regression using brms\")\n\n\n\n\n\n\n\n\nNow, for the effects plots I will only provide the effect plot from the model using lme4, as they are identical.\n\n# Plot the effects of the model\nplot(allEffects(model_glmer), main = \"Effects of Predictors on Contraception Use\")\n\n\n\n\n\n\n\n\nThe set of plots illustrates the effects of three predictors—age, number of living children (livch), and urban residency (urban)—on contraception use, based on model estimates. The first plot shows a non-linear relationship between age and contraception use, with usage peaking around the middle age range and decreasing at both younger and older ages. The shaded area represents the 95% confidence interval for the predicted values. The second plot highlights a positive association between the number of living children and contraception use, where usage increases significantly from 0 to 3+ children, stabilizing for the highest category. The third plot compares contraception use between urban and non-urban residents, indicating higher usage among urban residents, with error bars denoting the confidence intervals. These findings suggest that all three predictors—age, livch, and urban—significantly influence contraception use patterns."
  },
  {
    "objectID": "Project_5.html#package-comparisson",
    "href": "Project_5.html#package-comparisson",
    "title": "Project 5",
    "section": "Package Comparisson",
    "text": "Package Comparisson\n\nmodels_list &lt;- list(\n  model_glmer = model_glmer,\n  glmmPQL_model = glmmPQL_model,\n  model_brms = model_brms\n)\n\n# Extract and arrange fixed effect coefficients for comparison\nfixed_effects_comparison &lt;- purrr::map_dfr(models_list, ~tidy(., effects = \"fixed\", conf.int=TRUE), .id = \"model\") |&gt;\n  dplyr::arrange(term)\n\n# View the comparison\nfixed_effects_comparison[12,3] &lt;- \"livch3+\"\nfixed_effects_comparison[17,3] &lt;- \"ns(age, df = 2)1\"\nfixed_effects_comparison[18,3] &lt;- \"ns(age, df = 2)2\"\nhead(fixed_effects_comparison)\n\n# A tibble: 6 × 11\n  model   effect term  estimate std.error statistic   p.value conf.low conf.high\n  &lt;chr&gt;   &lt;chr&gt;  &lt;chr&gt;    &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;     &lt;dbl&gt;\n1 model_… fixed  (Int…   -1.90      0.181    -10.5   8.33e-26   -2.25      -1.54\n2 glmmPQ… fixed  (Int…   -1.85      0.175    -10.6   1.59e-25   -2.19      -1.51\n3 model_… fixed  (Int…   -1.91      0.180     NA    NA          -2.26      -1.55\n4 model_… fixed  livc…    0.831     0.165      5.03  5.00e- 7    0.507      1.16\n5 glmmPQ… fixed  livc…    0.812     0.160      5.08  4.12e- 7    0.499      1.13\n6 model_… fixed  livc…    0.837     0.163     NA    NA           0.517      1.15\n# ℹ 2 more variables: df &lt;dbl&gt;, component &lt;chr&gt;\n\n# Plot fixed effects using ggplot2\nggplot(fixed_effects_comparison, aes(x = estimate, y = model, color = model)) +\n  geom_point() +\n  geom_errorbarh(aes(xmin = estimate - std.error, xmax = estimate + std.error), height = 0.2) +\n  facet_wrap(~term, scales = \"free\") +\n  labs(title = \"Coefficient Plot of Fixed Effects\",\n       x = \"Estimate\",\n       y = \"Model\") +\n  theme_minimal()\n\n\n\n\n\n\n\n\nThe coefficient plot visualizes fixed-effect estimates for three different models: model_glmer, model_brms, and glmmPQL_model, across predictors including natural splines for age (ns(age, df=2)), number of living children (livch1, livch2, livch3+), and urban residency (urbanY). The plot demonstrates that the models produce consistent estimates with overlapping confidence intervals for most predictors, particularly for model_glmer and model_brms, which align closely. In contrast, glmmPQL_model exhibits more variability and narrower confidence intervals, diverging slightly for some coefficients. Notably, the Intercept and ns(age, df=2)[2] show a greater disparity between glmmPQL_model and the other two. These differences may reflect methodological variances in estimation techniques, underscoring the importance of model selection based on context and assumptions.\nPenalized Quasi-Likelihood (PQL) can be a valuable tool, especially in specific situations like smaller datasets, complex random effects structures, or when other methods face convergence challenges. However, the differences observed in your coefficient plot suggest that the divergence of glmmPQL_model from glmer and brms may stem from known limitations of the PQL approach, even within its intended use cases.\nPQL’s iterative nature and reliance on linearization at each step make it sensitive to the complexity of the model and the scale of the data. For example, in models with highly nonlinear relationships (such as those involving natural splines for age), the approximation process can lead to biased fixed-effect estimates. Furthermore, its point estimates might differ more noticeably when the sample size is small, as it does not fully maximize or integrate the likelihood like glmer or brms.\nWhile PQL is robust in avoiding convergence issues where likelihood-based methods might struggle, its performance might trade off precision or accuracy in parameter estimation. The observed discrepancies in your plot could therefore highlight the method’s limitations in fully capturing the variability or structure of the data compared to the more modern and computationally intensive approaches like maximum likelihood or Bayesian estimation.\nThis does not discredit PQL as a method but rather emphasizes its situational utility. In our case, it may be worth investigating whether data characteristics (e.g., the number of grouping levels or the distribution of the response variable) align with PQL’s strengths, or if model simplification could alleviate convergence issues in glmer or brms."
  },
  {
    "objectID": "Project_5.html#conclusion",
    "href": "Project_5.html#conclusion",
    "title": "Project 5",
    "section": "Conclusion",
    "text": "Conclusion\nThis analysis revisits the determinants of contraceptive use in Bangladesh, drawing on the 1989 Bangladesh Fertility Survey (BFS) and employing three multilevel logistic regression models: model_glmer, model_brms, and glmmPQL_model. The results reaffirm the significant roles of key predictors, including age, number of living children, and urban residency, in shaping contraceptive use patterns. The consistency of fixed-effect estimates across models, particularly between model_glmer and model_brms, strengthens the reliability of the findings, while the divergence observed in glmmPQL_model highlights the methodological differences inherent in estimation techniques.\nAs in the original study, urban residency and the number of living children are positively associated with contraceptive use. Urban women exhibit higher odds of adopting contraception (OR = 2.17, p &lt; 0.001), consistent with earlier findings linking urban residency to improved access to education, independence, and family planning resources. Similarly, the positive relationship between parity and contraceptive use aligns with previous conclusions, reinforcing the critical role of family size in influencing contraceptive decisions. The non-linear association between age and contraceptive use, with peak usage observed at middle ages, complements the original study’s findings and provides additional granularity to demographic trends.\nThe scatterplot of random intercepts and random effects of urban residency revealed an inverse relationship, indicating that districts with higher urban residency impacts tend to have lower baseline levels of contraceptive use. This suggests potential interactions between district-level characteristics and urban residency, echoing the original study’s emphasis on localized disparities in access to family planning resources. The hierarchical approach taken here further highlights how district-level variability shapes contraceptive use patterns and adds a layer of complexity to understanding urban-rural differences.\nLastly, the comparison of methods emphasizes the importance of model selection. While glmmPQL_model offers advantages in handling convergence issues, its divergence from model_glmer and model_brms suggests limitations in capturing non-linear relationships and hierarchical effects as effectively. These results suggest that maximum likelihood (glmer) and Bayesian methods (brms) provide more robust and accurate estimates for this type of analysis. Overall, the findings validate and expand upon the conclusions of the original study, offering updated insights into the demographic, socio-economic, and contextual factors that influence contraceptive use in Bangladesh."
  },
  {
    "objectID": "Project_5.html#references",
    "href": "Project_5.html#references",
    "title": "Project 5",
    "section": "References",
    "text": "References\n\nBarr, Dale J., Roger Levy, Christoph Scheepers, and Harry J. Tily. 2013. “Random Effects Structure for Confirmatory Hypothesis Testing: Keep It Maximal.” Journal of Memory and Language 68 (3): 255–78. https://doi.org/10.1016/j.jml.2012.11.001.\nBates, Douglas, Reinhold Kliegl, Shravan Vasishth, and Harald Baayen. 2015. “Parsimonious Mixed Models.” arXiv:1506.04967 [Stat], June. https://arxiv.org/abs/1506.04967.\nBates, Douglas, Martin Mächler, Ben Bolker, and Steve Walker. 2015. “Fitting Linear MixedEffects Models Using Lme4.” Journal of Statistical Software 67 (October): 1–48. https://doi. org/10.18637/jss.v067.i01.\nBiswas, Keya. 2015. “Performances of Different Estimation Methods for Generalized Linear Mixed Models.” Master’s thesis, McMaster University. https://macsphere.mcmaster.ca/ bitstream/11375/17272/2/M.Sc_Thesis_final_Keya_Biswas.pdf.\nBolker, Benjamin M. 2015. “Generalized Linear Mixed Models.” In Ecological Statistics: Contemporary Theory and Application, edited by Gordon A. Fox, Simoneta Negrete-Yankelevich, and Vinicio J. Sosa. Oxford University Press.\nBolker, Benjamin M. 2008. “Ecological Models and Data in R”\nBooth, James G., and James P. Hobert. 1999. “Maximizing Generalized Linear Mixed Model Likelihoods with an Automated Monte Carlo EM Algorithm.” Journal of the Royal Statistical Society. Series B 61 (1): 265–85. https://doi.org/10.1111/1467-9868.00176.\nBreslow, N. E. 2004. “Whither PQL?” In Proceedings of the Second Seattle Symposium in Biostatistics: Analysis of Correlated Data, edited by Danyu Y. Lin and P. J. Heagerty, 1–22. Springer.\nCrawley, Michael J. 2002. Statistical Computing: An Introduction to Data Analysis Using S-PLUS. John Wiley & Sons.\nGelman, Andrew. 2005. “Analysis of Variance: Why It Is More Important Than Ever.” Annals of Statistics 33 (1): 1–53. https://doi.org/doi:10.1214/009053604000001048.\nGelman, Andrew and Jakulin, Aleks and Pittau, Maria Grazia and Su, Yu-Sung, 2008. “A weakly informative default prior distribution for logistic & other regression models”\nK. Banos, 20024. “Assignment 2”\nMatuschek, Hannes, Reinhold Kliegl, Shravan Vasishth, Harald Baayen, and Douglas Bates.\n\n“Balancing Type I Error and Power in Linear Mixed Models.” Journal of Memory and Language 94 (June): 305–15. https://doi.org/10.1016/j.jml.2017.01.001.\n\nMurtaugh, Paul A. 2007. “Simplicity and Complexity in Ecological Data Analysis.” Ecology 88 (1): 56–62. http://www.esajournals.org/doi/abs/10.1890/0012-9658%282007%2988%5B5 6%3ASACIED%5D2.0.CO%3B2.\nPinheiro, José C., and Douglas M. Bates. 1996. “Unconstrained Parametrizations for VarianceCovariance Matrices.” Statistics and Computing 6 (3): 289–96. https://doi.org/10.1007/BF\n\n\n\nPonciano, José Miguel, Mark L. Taper, Brian Dennis, and Subhash R. Lele. 2009. “Hierarchical Models in Ecology: Confidence Intervals, Hypothesis Testing, and Model Selection Using Data Cloning.” Ecology 90 (2): 356–62. http://www.jstor.org/stable/27650990.\nStroup, Walter W. 2014. “Rethinking the Analysis of Non-Normal Data in Plant and Soil Science.” Agronomy Journal 106: 1–17. https://doi.org/10.2134/agronj2013.0342.\nSung, Yun Ju, and Charles J. Geyer. 2007. “Monte Carlo Likelihood Inference for Missing Data Models.” The Annals of Statistics 35 (3): 990–1011. https://doi.org/10.1214/009053606000\nHarrell, Frank E. 2015. “Regression Modeling Strategies: With Applications to Linear Models, Logistic and Ordinal Regression, and Survival Analysis”\nI read assignments for previous years in order to gain some great code ideas and identify previous mistakes inorder to avoid them.\nI used Chat Gpt extensively to create reports (I was writting my conclusions and after that, I was asking Chat Gpt to write it in a formal way as a report).\nI used chat-gpt to code some plots I didnt know and create a more professional output."
  },
  {
    "objectID": "Project_2.html",
    "href": "Project_2.html",
    "title": "Project 2",
    "section": "",
    "text": "library(mlmRev)           ## LOADING OF THE NECESSARY PACKAGES ##\nlibrary(tidyverse)\nlibrary(MASS)\nlibrary(lme4)\nlibrary(ggplot2)\nlibrary(performance)\nlibrary(DHARMa)\nlibrary(dotwhisker)\nlibrary(coefplot)\nlibrary(bbmle)\nlibrary(brglm2)\nlibrary(brms)\nlibrary(arm)\nlibrary(lmtest)\nlibrary(boot)\nlibrary(effects)\nlibrary(sjPlot)\nlibrary(AER)\nlibrary(pscl)\nlibrary(patchwork)"
  },
  {
    "objectID": "Project_2.html#a.-data-analysis-description",
    "href": "Project_2.html#a.-data-analysis-description",
    "title": "Project 2",
    "section": "a. Data Analysis Description",
    "text": "a. Data Analysis Description\nThis dataset originates from the 1988 Bangladesh Fertility Survey and includes a sub-sample of 1,934 women distributed across 60 districts.\nAccording to Harrell’s guidelines [@harrell], the optimal number of predictor variables in a logistic regression model should not exceed \\(\\frac{m}{15}\\), where m represents the limiting sample size, defined as m = nrow(Contraception). Given the current sample size, this criterion allows for the inclusion of the full number of predictor variables in the model.\nFurthermore, it is essential to establish a threshold for assessing the significance of predictor variables. In this analysis, a threshold of 5% for the variable age and 10% for the other predictors will be employed. Specifically, if a unit change in any predictor variable results a change greater than 5% or 10%, respectively in the response variable, this effect will be considered statistically significant. (I decided to use different thresholds in every predictor because the units are different and my sense telling me that it is not the same one year of change and an additional kid for example)\nMy approach involves a basic logistic regression model, which utilizes the binomial family and a logit link function. This model is appropriate given the binary nature of the response variable, use_num, where a value of 1 indicates the use of contraception and 0 indicates non-use.\n\nPredictors:\n\nCentered Age of Women (age):\nThe first predictor is the centered age of women. Based on intuitive reasoning, it is hypothesized that the relationship between women’s age and contraception use resembles an inverted U-shape. This suggests that both younger and older women are likely to use contraception less frequently than middle-aged women, making age a relevant predictor in the model.\nNumber of Living Children (livch):\nThe second predictor is the number of living children. It is posited that as individuals find a permanent partner, they tend to use contraception less frequently. Therefore, the presence of children is expected to correlate with contraception usage, making this a reasonable predictor to include in the model.\nType of Residence (urban):\nThe third and final predictor is the type of residence, categorized as urban or rural. Contraception use is strongly correlated with various socio-economic factors. For instance, urban areas that are wealthier tend to have higher levels of education. It is generally observed that individuals with higher educational attainment are more likely to use contraception. Thus, the type of residence is anticipated to be a significant predictor of contraception use.\n\nI decide not to include the district at the first model because I can save a lot of degrees of freedom by using only the type of residence. However, I may lose some important information and eventually, the model’s fit is not good enough\nIf the first model is inadequate to fit the dataset properly, a second approach would possibly involves a two-level main effect logistic regression model by including a random intercept for each district. This model will capture the variability at the district level, providing more accurate estimates if there are significant differences in contraceptive use between districts. It is widely known that it is especially useful for hierarchical data structures. The model will utilize the binomial family and a logit link function (I am gonna use this model if the overall fit of the first one is not good)."
  },
  {
    "objectID": "Project_2.html#b.-data-visualization",
    "href": "Project_2.html#b.-data-visualization",
    "title": "Project 2",
    "section": "b. Data Visualization",
    "text": "b. Data Visualization\nThe visualizations include bar plots and histograms that elucidate the relationships between contraceptive use, number of living children, urban or rural residence, district, and the age of women.\n\n# Function to create bar plots for contraceptive use by a given categorical variable\ncreate_bar_plot &lt;- function(data, x_var, x_label) {\n  ggplot(data, aes(x = .data[[x_var]], fill = factor(use_num))) + \n    geom_bar(position = \"fill\") +\n    labs(x = x_label, \n         y = \"Proportion of Contraceptive Use\", \n         fill = \"Contraceptive Use\") +\n    theme_minimal() +\n    scale_fill_manual(values = c(\"0\" = \"#E69F00\", \"1\" = \"#56B4E9\"), \n                      labels = c(\"No\", \"Yes\")) +\n    theme(legend.position = \"top\")\n}\n\n## CONTRACEPTION  VS LIVING CHILDREN BAR PLOT\ncreate_bar_plot(Contraception, \"livch\", \"Number of Living Children\")\n\n\n\n\n\n\n\n\n\ni) Proportion of Contraceptive Use by Number of Living Children\nThe bar plot depicting the proportion of contraceptive use by the number of living children reveals a clear trend. As the number of living children increases, there is a noticeable variation in the proportion of women using contraception. Specifically, women with fewer children are less likely to use contraception compared to those with more children. This suggests that family size may influence contraceptive decisions, indicating a potential focus area for family planning programs.\n\n## CONTRACEPTION  VS URBAN BAR PLOT\ncreate_bar_plot(Contraception, \"urban\", \"Residence (Urban/Rural)\")\n\n\n\n\n\n\n\n\n\n\nii) Proportion of Contraceptive Use by Urban or Rural Residence\nThe second bar plot compares contraceptive use between women residing in urban and rural areas. The results show that women living in urban areas have a higher proportion of contraceptive use compared to their rural counterparts.\n\n## CONTRACEPTION  VS DISTRICT BAR PLOT\ncreate_bar_plot(Contraception, \"district\", \"District\")\n\n\n\n\n\n\n\n\n\n\niii) Proportion of Contraceptive Use by District\nThe bar plot by district illustrates the variations in contraceptive use across different geographical regions. Each district exhibits unique patterns in contraceptive use, indicating that local policies, health services, and cultural factors may significantly influence these behaviors.\n\n# Function to create histograms for age distribution\ncreate_histogram &lt;- function(data, use_num, color, title) {\n  hist(data$age[data$use_num == use_num], \n       xlab = \"Age (Centered)\", \n       ylab = \"Frequency\", \n       main = title, \n       col = color, \n       border = \"white\")\n}\n\n# Create histograms for age distribution and Non-Contraceptive Users\ncreate_histogram(Contraception, 0, \"#E69F00\", \"Age Distribution: Non-Contraceptive Users\")\n\n\n\n\n\n\n\n\n\n\niv) Age Distribution of Non-Contraceptive Users\nThe histogram showing the age distribution of women who do not use contraception indicates a concentration of non-users in younger age groups. This suggests that younger women may either have limited knowledge about contraceptive options or may not yet feel the need for contraception. Addressing knowledge gaps.\n\n# Create histograms for age distribution for Contraceptive Users\ncreate_histogram(Contraception, 1, \"#56B4E9\", \"Age Distribution: Contraceptive Users\")\n\n\n\n\n\n\n\n\n\n\nv)Age Distribution of Contraceptive Users\nThis histogram showcases the age distribution for women who do use contraception, similar to the previous plot but focused on users. As we had anticipated the distribution appears to be more evenly spread across age groups, with a notable presence of users in the middle and older age groups.\n\ncreate_box_plot &lt;- function(data) {\n  boxplot(age ~ use_num, \n          data = data, \n          xlab = \"Contraceptive Use (0 = Non-Users, 1 = Users)\", \n          ylab = \"Age (Centered)\", \n          main = \"Age Distribution by Contraceptive Use\", \n          col = c(\"#E69F00\", \"#56B4E9\"), \n          border = \"darkgray\")\n}\n\n# Create the box plot for age distribution\ncreate_box_plot(Contraception)"
  },
  {
    "objectID": "Project_2.html#c.-model-fit",
    "href": "Project_2.html#c.-model-fit",
    "title": "Project 2",
    "section": "c. Model Fit",
    "text": "c. Model Fit\n\n# Fit the logistic regression model\nmodel &lt;- glm(use_num ~ age + livch + urban, \n             data = Contraception, \n             family = binomial(link = \"logit\"))\n\nsummary(model)\n\n\nCall:\nglm(formula = use_num ~ age + livch + urban, family = binomial(link = \"logit\"), \n    data = Contraception)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.568044   0.126229 -12.422  &lt; 2e-16 ***\nage         -0.023995   0.007536  -3.184  0.00145 ** \nlivch1       1.059186   0.151954   6.970 3.16e-12 ***\nlivch2       1.287805   0.167241   7.700 1.36e-14 ***\nlivch3+      1.216385   0.170593   7.130 1.00e-12 ***\nurbanY       0.797181   0.105186   7.579 3.49e-14 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 2590.9  on 1933  degrees of freedom\nResidual deviance: 2456.7  on 1928  degrees of freedom\nAIC: 2468.7\n\nNumber of Fisher Scoring iterations: 4"
  },
  {
    "objectID": "Project_2.html#d.-comparison-of-the-diagnostic-plots",
    "href": "Project_2.html#d.-comparison-of-the-diagnostic-plots",
    "title": "Project 2",
    "section": "d. Comparison of the Diagnostic Plots",
    "text": "d. Comparison of the Diagnostic Plots\n\nperformance::check_model(model, panel = TRUE)\n\n\n\n\n\n\n\n\n\ni) Posterior Predictive Check:\nThe observed and model-predicted intervals seem close, suggesting a reasonable fit.\n\n\nii) Binned Residuals:\nThe plot shows the model’s errors across the probability range, and most residuals fall within the bounds, meaning no strong deviations, but a few points (in red) indicate areas with potential under- or over-prediction. Looking at the graph, there is possibility for overfitting but not something terrible. A good practice to detect data overfitting is by applying Cross-Validation, Bootstrap Resampling etc.\nBelow I am going test if there is an overfitting problem to my model by using a Bootstrap Resampling algorithm. This will give us a distribution of model coefficients across different resampled datasets, showing how much they vary.\n\nset.seed(123)\nboot_fit &lt;- boot(data=Contraception, statistic=function(data, indices) {\n  d &lt;- data[indices, ]\n  fit &lt;- glm(use_num ~ age + livch + urban, data=d, family=binomial(link=\"logit\"))\n  return(coef(fit))\n}, R=1000)\nboot_fit\n\n\nORDINARY NONPARAMETRIC BOOTSTRAP\n\n\nCall:\nboot(data = Contraception, statistic = function(data, indices) {\n    d &lt;- data[indices, ]\n    fit &lt;- glm(use_num ~ age + livch + urban, data = d, family = binomial(link = \"logit\"))\n    return(coef(fit))\n}, R = 1000)\n\n\nBootstrap Statistics :\n       original        bias    std. error\nt1* -1.56804374 -0.0067118991 0.123053057\nt2* -0.02399512 -0.0001941084 0.007193948\nt3*  1.05918582  0.0065718308 0.155691426\nt4*  1.28780501  0.0024604551 0.162848757\nt5*  1.21638466  0.0035732271 0.165559373\nt6*  0.79718138  0.0052819863 0.105728152\n\n\n\nboot_df &lt;- as.data.frame(boot_fit$t)\nnames(boot_df) &lt;- names(boot_fit$t0)\n\nboot_long &lt;- boot_df %&gt;%\n  pivot_longer(everything(), names_to = \"term\", values_to = \"beta\")\n\nci_df &lt;- boot_long %&gt;%\n  group_by(term) %&gt;%\n  summarise(\n    mean = mean(beta),\n    lo = quantile(beta, 0.025),\n    hi = quantile(beta, 0.975),\n    .groups = \"drop\"\n  )\n\nggplot(boot_long, aes(x = beta)) +\n  geom_histogram(bins = 35) +\n  facet_wrap(~ term, scales = \"free\", ncol = 3) +\n  geom_vline(data = ci_df, aes(xintercept = mean), linewidth = 0.6) +\n  geom_vline(data = ci_df, aes(xintercept = lo), linetype = \"dashed\", linewidth = 0.5) +\n  geom_vline(data = ci_df, aes(xintercept = hi), linetype = \"dashed\", linewidth = 0.5) +\n  labs(\n    title = \"Bootstrap distributions of coefficient estimates\",\n    subtitle = \"Solid = mean; dashed = 95% percentile interval (R = 1000)\",\n    x = \"Coefficient estimate\",\n    y = \"Count\"\n  ) +\n  theme_minimal(base_size = 12) +\n  theme(\n    plot.title = element_text(face = \"bold\", hjust = 0.5),\n    plot.subtitle = element_text(hjust = 0.5)\n  )\n\n\n\n\n\n\n\n\n\nThe bias for all coefficients is relatively small, which is a good sign that the bootstrap estimates closely match the original estimates.\nThe standard errors are also within reasonable ranges, indicating that the coefficients are relatively stable across the bootstrapped samples. However, livch and urban coefficients have somewhat higher variability compared to age.\n\nThis result suggests that the model is not overfitting, as the coefficients appear stable with small bias and reasonable variability. I run that bootstrap algorithm in order to support the robustness of my model.\n\n\niii) Influential Observations:\nThis plot identifies points with high leverage (potentially influential points) based on the distance of their leverage (horizontal axis) and standardized residuals (vertical axis).\n\n\niv) Collinearity:\nAll predictors have a VIF below 5, which suggests no problematic collinearity that might affect model stability.\n\nsimulated_residuals &lt;- simulateResiduals(\n  fittedModel = model\n  )\n\nplot(simulated_residuals)\n\n\n\n\n\n\n\n\n\n\ni) QQ Plot of Residuals:\nSince the residuals fall almost perfectly along the line, this indicates that they are well-behaved and likely normally distributed. The Kolmogorov-Smirnov (KS) test shows no significant deviation from expectations (p-values &gt; 0.05).\n\n\nii) Residual vs. Predicted (Rank Transformed):\nThe random scatter of residuals and lack of any clear pattern indicate that the model fits well, with no significant problems detected.\nEventually, I am not going to use the second model or any adjustment to the model as the first one seems to have a reasonable good fit without violating the assumptions."
  },
  {
    "objectID": "Project_2.html#e.-results-interpretation-and-coefficienteffect-plots",
    "href": "Project_2.html#e.-results-interpretation-and-coefficienteffect-plots",
    "title": "Project 2",
    "section": "e. Results Interpretation and Coefficient/Effect Plots",
    "text": "e. Results Interpretation and Coefficient/Effect Plots\n\n# Coefficient plot with `theme_minimal()`\nplot_model(model, \n            show.values = TRUE, \n            value.offset = 0.3,\n            title = \"Coefficient Plot of Logistic Regression\") + \n  theme_minimal()\n\n\n\n\n\n\n\n# Plot the effects of the model\nplot(allEffects(model), main = \"Effects of Predictors on Contraception Use\")\n\n\n\n\n\n\n\n\nThe log-odds coefficients can be converted into odds ratios (OR) by exponentiating the coefficients. This helps in understanding the percentage change in the odds of the response variable. The odds ratio tells us the multiplicative change in the odds of the outcome for a one-unit change in the predictor. If the odds ratio is above 1, the odds of the event increase; if below 1, the odds decrease.\n\nage: The odds ratio is exp⁡(−0.023995) = 0.976, meaning that for each additional year of age, the odds of using contraception decrease by about 2.4%. This is less than the 5% threshold, so while it’s statistically significant, it did not meet our criteria for a practically significant effect.\nlivch1: The odds ratio for having one child is exp⁡(1.059) = 2.884, meaning the odds of using contraception are 188.4% higher compared to women with no children and much higher from 10% (our threshold).\nlivch2: The odds ratio for having two children is exp⁡(1.288) = 3.626, meaning the odds of using contraception are 262.6% higher compared to women with no children and much higher from 10% (our threshold).\nlivch3+: The odds ratio for having three or more children is exp⁡(1.216) = 3.375, meaning the odds of using contraception are 237.5% higher compared to women with no children and much higher from 10% (our threshold).\nurbanY: The odds ratio is exp⁡(0.797) = 2.219, meaning living in an urban area increases the odds of using contraception by 121.9% compared to rural areas and much higher from 10% (our threshold).\n\nThe predictors livch and urban have strong and significant effects on the odds of using contraception, with odds ratios well above 1, meaning their effects are both statistically and practically significant based on our 10% threshold.\nIn the logistic regression model examining the use of contraception (use_num) based on age, livch (number of living children), and urban (urban vs. non-urban), categorical predictors were automatically encoded by R into dummy variables. Specifically, livch and urban are categorical variables, and R created separate coefficients for each level of livch (e.g., livch1, livch2, livch3+), comparing each to a reference category (livch = 0). Similarly, for urban, the coefficient urbanY compares living in an urban area (Y) to the reference group living in a non-urban area (N). These coefficients reflect the change in the log-odds of using contraception compared to the reference categories. This encoding allows for a detailed understanding of how each level of the categorical variables affects the likelihood of using contraception."
  },
  {
    "objectID": "Project_2.html#a.-data-visualization",
    "href": "Project_2.html#a.-data-visualization",
    "title": "Project 2",
    "section": "a. Data Visualization",
    "text": "a. Data Visualization\n\n# Line plot\nggplot(g_data, aes(x = year, y = shells, color = Site, group = Site)) +\n  geom_line(size = 1.2) +  # Line size for visibility\n  geom_point(size = 3, shape = 21, fill = \"black\") +  # Points with white fill for better contrast\n  labs(\n    title = \"Trends in Gopher Shell Counts Over Time by Site\",\n    x = \"Year\",\n    y = \"Number of Shells\",\n    color = \"Site\"  # Legend title\n  ) +\n  theme_minimal(base_size = 12) +  # Clean theme\n  theme(\n    legend.position = \"right\",  # Legend positioning\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),  # Smaller centered title\n    axis.title = element_text(size = 10),  # Axis title size\n    axis.text = element_text(size = 9)  # Axis text size\n  ) +\n  scale_color_brewer(palette = \"Set3\")  # Color palette\n\n\n\n\n\n\n\n\n\nThe first plot shows the variability in shell numbers across different sites and years, with some showing increasing or decreasing trends.\n\n\n# Scatterplot\nggplot(g_data, aes(x = prev, y = shells, color = type)) +\n  geom_point(size = 3, alpha = 0.7, shape = 21, fill = \"grey\") +  # Points with transparency\n  labs(\n    title = \"Relationship Between Shell Counts and Seroprevalence\",\n    x = \"Seroprevalence\",\n    y = \"Number of Shells\",\n    color = \"Type\"  # Legend title\n  ) +\n  geom_smooth(se = FALSE, method = \"loess\", color = \"lightblue\", formula = y ~ x) +  # Smooth line\n  theme_minimal(base_size = 12) +  # Clean theme\n  theme(\n    legend.position = \"right\",  # Legend positioning\n    plot.title = element_text(hjust = 0.5, size = 14, face = \"bold\"),  # Smaller centered title\n    axis.title = element_text(size = 10),  # Axis title size\n    axis.text = element_text(size = 9)  # Axis text size\n  ) +\n  scale_color_brewer(palette = \"Set2\")  # Color palette\n\n\n\n\n\n\n\n\n\nThe second plot suggests a positive correlation between seroprevalence and the number of shells, particularly when seroprevalence is high."
  },
  {
    "objectID": "Project_2.html#b.-model-fit",
    "href": "Project_2.html#b.-model-fit",
    "title": "Project 2",
    "section": "b. Model Fit",
    "text": "b. Model Fit\nIn this analysis, the response variable is the count of shells, making a Poisson Regression Model an appropriate choice given the nature of the data. To ensure robust estimation, we will adhere to the rule of requiring at least 10-20 observations per predictor. Therefore, the number of predictors will be minimized to meet this criterion, balancing model complexity and data sufficiency for accurate inference.\n\n## Model Fit\npoisson_model &lt;- glm(shells ~ year_c + prev + offset(log(Area)), data = g_data, family = poisson(link = \"log\"))\nsummary(poisson_model)\n\n\nCall:\nglm(formula = shells ~ year_c + prev + offset(log(Area)), family = poisson(link = \"log\"), \n    data = g_data)\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -3.557101   0.241276 -14.743  &lt; 2e-16 ***\nyear_c      -0.229100   0.164966  -1.389    0.165    \nprev         0.021828   0.004326   5.045 4.52e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for poisson family taken to be 1)\n\n    Null deviance: 49.800  on 29  degrees of freedom\nResidual deviance: 24.317  on 27  degrees of freedom\nAIC: 84.172\n\nNumber of Fisher Scoring iterations: 5\n\n## Over-dispersion Check\ndispersion &lt;- summary(poisson_model)$deviance / summary(poisson_model)$df.residual\nprint(c(\"Dispersion =\", dispersion))\n\n[1] \"Dispersion =\"      \"0.900646372066475\"\n\ndispersiontest(poisson_model)\n\n\n    Overdispersion test\n\ndata:  poisson_model\nz = -1.0315, p-value = 0.8488\nalternative hypothesis: true dispersion is greater than 1\nsample estimates:\ndispersion \n 0.7688125 \n\n\nThe dispersion statistic is calculated as 0.901, which is less than 1, indicating that the model does not exhibit overdispersion (The results of the dispersion test further confirm this, with a test statistic of -1.0315 and a p-value of 0.8488), so Poisson-Regression is an appropriate model for the problem."
  },
  {
    "objectID": "Project_2.html#c.-model-fit-using-bbmle",
    "href": "Project_2.html#c.-model-fit-using-bbmle",
    "title": "Project 2",
    "section": "c. Model Fit Using bbmle",
    "text": "c. Model Fit Using bbmle\n\n## Transforming year as a factor\ng_data &lt;- transform(\n  g_data,\n  year = as.factor(year)\n  )\n\n# Fit the Poisson model using bbmle formula interface\npoisson_model_bbmle &lt;-  mle2(shells ~ dpois(lambda = exp(b0 + b1 * year_c                                  + b2 * prev + log(Area))),\n                             start = list(b0 = 0, b1 = 0, b2 = 0),\n                             data = g_data) \n\nsummary(poisson_model_bbmle)\n\nMaximum likelihood estimation\n\nCall:\nmle2(minuslogl = shells ~ dpois(lambda = exp(b0 + b1 * year_c + \n    b2 * prev + log(Area))), start = list(b0 = 0, b1 = 0, b2 = 0), \n    data = g_data)\n\nCoefficients:\n     Estimate Std. Error  z value     Pr(z)    \nb0 -3.5563450  0.2412167 -14.7434 &lt; 2.2e-16 ***\nb1 -0.2283314  0.1649610  -1.3842    0.1663    \nb2  0.0218136  0.0043262   5.0422 4.601e-07 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n-2 log L: 78.17166 \n\n\nThe results obtained from the Poisson regression models fitted using the glm() function and the bbmle::mle2() function are notably similar, indicating consistency across both methodologies. Furthermore, if the original factor variable for year is employed in the glm() model, the estimates would closely align with those derived from the bbmle approach."
  },
  {
    "objectID": "Project_2.html#d.-creation-of-a-negative-log-likelihood-function",
    "href": "Project_2.html#d.-creation-of-a-negative-log-likelihood-function",
    "title": "Project 2",
    "section": "d. Creation of a Negative Log-likelihood Function",
    "text": "d. Creation of a Negative Log-likelihood Function\n\n# the Negative Log-Likelihood\nNGLL &lt;- function(b0, b1, b2) {\n  lamda &lt;- exp(b0 + b1 * g_data$year_c + b2 * g_data$prev + log(g_data$Area)) \n  negative_log_likelihood &lt;- -sum(dpois(g_data$shells, lambda = lamda, log = TRUE))\n  \n  return(negative_log_likelihood)\n}\n\n## NGLL(0,0,0)    ## Test\n\n# Using optim to Minimize the Negative Log-Likelihood\nmy_optim &lt;- optim(par = c(b0 = 0, b1 = 0, b2 = 0), \n                   fn = function(params) \n                     NGLL(params[1], params[2], params[3]))"
  },
  {
    "objectID": "Project_2.html#e.-comparison-of-parameters-for-different-approaches",
    "href": "Project_2.html#e.-comparison-of-parameters-for-different-approaches",
    "title": "Project 2",
    "section": "e. Comparison of Parameters for Different Approaches",
    "text": "e. Comparison of Parameters for Different Approaches\n\n## Estimates from poisson_model\npoisson_model_params &lt;- coef(poisson_model)\n  \n## Estimates from poisson_model_bbmle\npoisson_model_bbmle_params &lt;- coef(poisson_model_bbmle)\n  \n## Estimates from my_optim\nmy_optim_params &lt;- my_optim$par\n  \n# Creation of a data frame\ncomparisons &lt;- data.frame(\n    poisson_model = poisson_model_params,\n    poisson_model_bbmle = poisson_model_bbmle_params,\n    my_optim = my_optim_params\n  )\nprint(comparisons)  \n\n            poisson_model poisson_model_bbmle    my_optim\n(Intercept)   -3.55710147         -3.55634500 -3.55661473\nyear_c        -0.22909974         -0.22833145 -0.22926177\nprev           0.02182806          0.02181357  0.02182335\n\n\nAs we expected, the coefficients of all methods are nearly identical."
  },
  {
    "objectID": "Project_2.html#f.-wald-and-profile-cis",
    "href": "Project_2.html#f.-wald-and-profile-cis",
    "title": "Project 2",
    "section": "f. Wald and profile CIs",
    "text": "f. Wald and profile CIs\n\n## WALD CIs for Poisson GLM\n# Extract the standard errors and compute the Wald CI\npoisson_model_se &lt;- summary(poisson_model)$coefficients[, \"Std. Error\"]\nwald_ci_glm &lt;- confint.default(poisson_model, level = 0.95)  # Wald CI from GLM\n\n## WALD CIs for bbmle\n# Get standard errors from bbmle fit\npoisson_model_bbmle_se &lt;- sqrt(diag(vcov(poisson_model_bbmle)))\nwald_ci_bbmle &lt;- cbind(\n  poisson_model_bbmle_params - 1.96 * poisson_model_bbmle_se,\n  poisson_model_bbmle_params + 1.96 * poisson_model_bbmle_se\n)\n\n## WALD CIs for custom optim fit\n# Assume that the Hessian matrix (returned by optim) is an approximation of the covariance matrix\nhessian &lt;- optimHess(par = my_optim$par, fn = function(params) NGLL(params[1], params[2], params[3]))\ncov_matrix &lt;- solve(hessian)\noptim_se &lt;- sqrt(diag(cov_matrix))\n\n# Compute the Wald CIs for optim estimates\nwald_ci_optim &lt;- cbind(\n  my_optim_params - 1.96 * optim_se,\n  my_optim_params + 1.96 * optim_se\n)\n\n## PROFILE CIs for bbmle\nprofile_ci_bbmle &lt;- confint(poisson_model_bbmle)\n\n## Print Wald CIs and compare\nwald_comparison &lt;- data.frame(\n  Parameter = names(poisson_model_params),\n  Wald_CI_GLM = paste0(round(wald_ci_glm[, 1], 4), \" to \", round(wald_ci_glm[, 2], 4)),\n  Wald_CI_bbmle = paste0(round(wald_ci_bbmle[, 1], 4), \" to \", round(wald_ci_bbmle[, 2], 4)),\n  Wald_CI_optim = paste0(round(wald_ci_optim[, 1], 4), \" to \", round(wald_ci_optim[, 2], 4))\n)\n\nprint(wald_comparison)\n\n    Parameter       Wald_CI_GLM      Wald_CI_bbmle      Wald_CI_optim\n1 (Intercept)  -4.03 to -3.0842 -4.0291 to -3.0836 -4.0293 to -3.0839\n2      year_c -0.5524 to 0.0942   -0.5517 to 0.095   -0.5526 to 0.094\n3        prev  0.0133 to 0.0303   0.0133 to 0.0303   0.0134 to 0.0303\n\n## Compare Profile CIs for bbmle\nprofile_ci_comparison &lt;- data.frame(\n  Parameter = names(poisson_model_bbmle_params),\n  Profile_CI_bbmle = paste0(round(profile_ci_bbmle[, 1], 4), \" to \", round(profile_ci_bbmle[, 2], 4))\n)\n\nprint(profile_ci_comparison)\n\n  Parameter   Profile_CI_bbmle\n1        b0 -4.0618 to -3.1126\n2        b1  -0.5554 to 0.0943\n3        b2   0.0134 to 0.0304\n\n\n\nWald Confidence Intervals Comparison:\n\nWald CI for GLM: These were calculated based on the standard errors from the GLM output. For example, for the intercept (b0​), the Wald CI ranges from -4.03 to -3.08.\nWald CI for bbmle: Similarly calculated using the standard errors from the bbmle model fit, yielding a very similar CI for b0 ​ (-4.0291 to -3.0836), showing that both methods are almost identical in their results.\nWald CI for optim: Using the Hessian matrix from optim as an estimate for the covariance matrix, the Wald CI for the intercept (b0​) was again very close to the previous estimates, ranging from -4.0293 to -3.0839.\n\nConclusion: The Wald CIs are very consistent across all three approaches, indicating that the parameter estimates are robust regardless of the method used to fit the model.\n\n\nProfile Confidence Intervals (for bbmle):\n\nThese CIs were calculated using profile likelihood, which often provides more accurate confidence intervals, particularly for non-linear models or when the parameters are near the boundary of their possible range.\nFor the intercept (b0​), the profile CI ranges from -4.0618 to -3.1126, which is slightly wider than the Wald CIs. Similarly, the CIs for the other parameters (b1​ and b2) are also slightly broader compared to the Wald CIs.\n\n\n\nComparison and Interpretation:\n\nWald vs Profile CIs: Wald CIs assume normality of the estimates and may be narrower, especially when the model is highly non-linear. Profile CIs are generally considered more accurate as they account for the curvature of the likelihood surface. In our case, the profile CIs are slightly wider, suggesting a more conservative estimate of uncertainty around the parameters.\nConsistency across methods: The similarity in Wald CIs from GLM, bbmle, and optim suggests that all methods are implemented correctly and are producing nearly identical parameter estimates.\n\nThis shows that both Wald and profile CIs are in good agreement, though the profile CIs provide a slightly more conservative interval, as expected. These comparisons also confirm that your implementations across different methods are consistent."
  }
]